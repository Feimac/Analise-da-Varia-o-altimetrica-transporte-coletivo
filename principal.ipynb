{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f74dbeed-f42a-4dad-8cce-f89ee4b3d72d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 17:37:11,133 - INFO - Iniciando processo de coleta de SHAPES a partir do arquivo: Linha.csv\n",
      "2025-05-26 17:37:11,141 - INFO - Encontrados 276 códigos de linha únicos para processamento de SHAPES: ['10', '11', '20', '21', '22', '23', '30', '40', '50', '60']... (mostrando até 10)\n",
      "2025-05-26 17:37:11,142 - INFO - Iniciando coleta de SHAPES com até 5 threads para 276 linhas únicas.\n",
      "2025-05-26 17:37:11,361 - INFO - SHAPE coletado para a linha 20 (982 pontos). Progresso: 1/276\n",
      "2025-05-26 17:37:11,371 - INFO - SHAPE coletado para a linha 11 (649 pontos). Progresso: 2/276\n",
      "2025-05-26 17:37:11,447 - INFO - SHAPE coletado para a linha 10 (665 pontos). Progresso: 3/276\n",
      "2025-05-26 17:37:11,517 - INFO - SHAPE coletado para a linha 22 (973 pontos). Progresso: 4/276\n",
      "2025-05-26 17:37:11,558 - INFO - SHAPE coletado para a linha 21 (1025 pontos). Progresso: 5/276\n",
      "2025-05-26 17:37:11,679 - INFO - SHAPE coletado para a linha 23 (961 pontos). Progresso: 6/276\n",
      "2025-05-26 17:37:11,819 - INFO - SHAPE coletado para a linha 60 (1266 pontos). Progresso: 7/276\n",
      "2025-05-26 17:37:11,832 - INFO - SHAPE coletado para a linha 30 (1680 pontos). Progresso: 8/276\n",
      "2025-05-26 17:37:11,922 - INFO - SHAPE coletado para a linha 50 (1256 pontos). Progresso: 9/276\n",
      "2025-05-26 17:37:11,961 - INFO - SHAPE coletado para a linha 40 (1974 pontos). Progresso: 10/276\n",
      "2025-05-26 17:37:12,023 - INFO - SHAPE coletado para a linha 150 (478 pontos). Progresso: 11/276\n",
      "2025-05-26 17:37:12,036 - INFO - SHAPE coletado para a linha 164 (243 pontos). Progresso: 12/276\n",
      "2025-05-26 17:37:12,153 - INFO - SHAPE coletado para a linha 160 (680 pontos). Progresso: 13/276\n",
      "2025-05-26 17:37:12,243 - INFO - SHAPE coletado para a linha 166 (594 pontos). Progresso: 14/276\n",
      "2025-05-26 17:37:12,251 - INFO - SHAPE coletado para a linha 168 (958 pontos). Progresso: 15/276\n",
      "2025-05-26 17:37:12,308 - INFO - SHAPE coletado para a linha 169 (560 pontos). Progresso: 16/276\n",
      "2025-05-26 17:37:12,374 - INFO - SHAPE coletado para a linha 170 (814 pontos). Progresso: 17/276\n",
      "2025-05-26 17:37:12,397 - INFO - SHAPE coletado para a linha 171 (713 pontos). Progresso: 18/276\n",
      "2025-05-26 17:37:12,440 - INFO - SHAPE coletado para a linha 175 (513 pontos). Progresso: 19/276\n",
      "2025-05-26 17:37:12,625 - INFO - SHAPE coletado para a linha 176 (539 pontos). Progresso: 20/276\n",
      "2025-05-26 17:37:12,643 - INFO - SHAPE coletado para a linha 177 (363 pontos). Progresso: 21/276\n",
      "2025-05-26 17:37:12,650 - INFO - SHAPE coletado para a linha 182 (813 pontos). Progresso: 22/276\n",
      "2025-05-26 17:37:12,772 - INFO - SHAPE coletado para a linha 183 (798 pontos). Progresso: 23/276\n",
      "2025-05-26 17:37:12,916 - INFO - SHAPE coletado para a linha 184 (632 pontos). Progresso: 24/276\n",
      "2025-05-26 17:37:12,967 - INFO - SHAPE coletado para a linha 189 (743 pontos). Progresso: 25/276\n",
      "2025-05-26 17:37:12,989 - INFO - SHAPE coletado para a linha 203 (800 pontos). Progresso: 26/276\n",
      "2025-05-26 17:37:13,008 - INFO - SHAPE coletado para a linha 181 (970 pontos). Progresso: 27/276\n",
      "2025-05-26 17:37:13,067 - INFO - SHAPE coletado para a linha 188 (1501 pontos). Progresso: 28/276\n",
      "2025-05-26 17:37:13,136 - INFO - SHAPE coletado para a linha 207 (633 pontos). Progresso: 29/276\n",
      "2025-05-26 17:37:13,142 - INFO - SHAPE coletado para a linha 205 (513 pontos). Progresso: 30/276\n",
      "2025-05-26 17:37:13,310 - INFO - SHAPE coletado para a linha 211 (383 pontos). Progresso: 31/276\n",
      "2025-05-26 17:37:13,315 - INFO - SHAPE coletado para a linha 212 (304 pontos). Progresso: 32/276\n",
      "2025-05-26 17:37:13,378 - INFO - SHAPE coletado para a linha 210 (1101 pontos). Progresso: 33/276\n",
      "2025-05-26 17:37:13,489 - INFO - SHAPE coletado para a linha 213 (329 pontos). Progresso: 34/276\n",
      "2025-05-26 17:37:13,505 - INFO - SHAPE coletado para a linha 214 (261 pontos). Progresso: 35/276\n",
      "2025-05-26 17:37:13,567 - INFO - SHAPE coletado para a linha 206 (1312 pontos). Progresso: 36/276\n",
      "2025-05-26 17:37:13,696 - INFO - SHAPE coletado para a linha 224 (140 pontos). Progresso: 37/276\n",
      "2025-05-26 17:37:13,702 - INFO - SHAPE coletado para a linha 222 (477 pontos). Progresso: 38/276\n",
      "2025-05-26 17:37:13,853 - INFO - SHAPE coletado para a linha 226 (264 pontos). Progresso: 39/276\n",
      "2025-05-26 17:37:13,944 - INFO - SHAPE coletado para a linha 225 (175 pontos). Progresso: 40/276\n",
      "2025-05-26 17:37:13,983 - INFO - SHAPE coletado para a linha 209 (693 pontos). Progresso: 41/276\n",
      "2025-05-26 17:37:13,997 - INFO - SHAPE coletado para a linha 216 (864 pontos). Progresso: 42/276\n",
      "2025-05-26 17:37:14,007 - INFO - SHAPE coletado para a linha 229 (751 pontos). Progresso: 43/276\n",
      "2025-05-26 17:37:14,081 - INFO - SHAPE coletado para a linha 231 (547 pontos). Progresso: 44/276\n",
      "2025-05-26 17:37:14,159 - INFO - SHAPE coletado para a linha 233 (241 pontos). Progresso: 45/276\n",
      "2025-05-26 17:37:14,191 - INFO - SHAPE coletado para a linha 236 (513 pontos). Progresso: 46/276\n",
      "2025-05-26 17:37:14,226 - INFO - SHAPE coletado para a linha 237 (233 pontos). Progresso: 47/276\n",
      "2025-05-26 17:37:14,292 - INFO - SHAPE coletado para a linha 238 (187 pontos). Progresso: 48/276\n",
      "2025-05-26 17:37:14,339 - INFO - SHAPE coletado para a linha 242 (249 pontos). Progresso: 49/276\n",
      "2025-05-26 17:37:14,398 - INFO - SHAPE coletado para a linha 232 (453 pontos). Progresso: 50/276\n",
      "2025-05-26 17:37:14,416 - INFO - SHAPE coletado para a linha 244 (376 pontos). Progresso: 51/276\n",
      "2025-05-26 17:37:14,451 - INFO - SHAPE coletado para a linha 243 (327 pontos). Progresso: 52/276\n",
      "2025-05-26 17:37:14,605 - INFO - SHAPE coletado para a linha 260 (646 pontos). Progresso: 53/276\n",
      "2025-05-26 17:37:14,732 - INFO - SHAPE coletado para a linha 266 (466 pontos). Progresso: 54/276\n",
      "2025-05-26 17:37:14,801 - INFO - SHAPE coletado para a linha 245 (1362 pontos). Progresso: 55/276\n",
      "2025-05-26 17:37:14,809 - INFO - SHAPE coletado para a linha 265 (856 pontos). Progresso: 56/276\n",
      "2025-05-26 17:37:14,849 - INFO - SHAPE coletado para a linha 250 (1548 pontos). Progresso: 57/276\n",
      "2025-05-26 17:37:14,887 - INFO - SHAPE coletado para a linha 272 (628 pontos). Progresso: 58/276\n",
      "2025-05-26 17:37:14,997 - INFO - SHAPE coletado para a linha 274 (614 pontos). Progresso: 59/276\n",
      "2025-05-26 17:37:15,096 - INFO - SHAPE coletado para a linha 303 (1149 pontos). Progresso: 60/276\n",
      "2025-05-26 17:37:15,127 - INFO - SHAPE coletado para a linha 280 (574 pontos). Progresso: 61/276\n",
      "2025-05-26 17:37:15,233 - INFO - SHAPE coletado para a linha 275 (1301 pontos). Progresso: 62/276\n",
      "2025-05-26 17:37:15,312 - INFO - SHAPE coletado para a linha 304 (1179 pontos). Progresso: 63/276\n",
      "2025-05-26 17:37:15,345 - INFO - SHAPE coletado para a linha 305 (439 pontos). Progresso: 64/276\n",
      "2025-05-26 17:37:15,356 - INFO - SHAPE coletado para a linha 308 (432 pontos). Progresso: 65/276\n",
      "2025-05-26 17:37:15,368 - INFO - SHAPE coletado para a linha 307 (1030 pontos). Progresso: 66/276\n",
      "2025-05-26 17:37:15,433 - INFO - SHAPE coletado para a linha 309 (416 pontos). Progresso: 67/276\n",
      "2025-05-26 17:37:15,465 - INFO - SHAPE coletado para a linha 311 (138 pontos). Progresso: 68/276\n",
      "2025-05-26 17:37:15,518 - INFO - SHAPE coletado para a linha 322 (158 pontos). Progresso: 69/276\n",
      "2025-05-26 17:37:15,542 - INFO - SHAPE coletado para a linha 323 (192 pontos). Progresso: 70/276\n",
      "2025-05-26 17:37:15,585 - INFO - SHAPE coletado para a linha 321 (281 pontos). Progresso: 71/276\n",
      "2025-05-26 17:37:15,651 - INFO - SHAPE coletado para a linha 331 (96 pontos). Progresso: 72/276\n",
      "2025-05-26 17:37:15,688 - INFO - SHAPE coletado para a linha 332 (251 pontos). Progresso: 73/276\n",
      "2025-05-26 17:37:15,730 - INFO - SHAPE coletado para a linha 334 (213 pontos). Progresso: 74/276\n",
      "2025-05-26 17:37:15,811 - INFO - SHAPE coletado para a linha 336 (424 pontos). Progresso: 75/276\n",
      "2025-05-26 17:37:15,823 - INFO - SHAPE coletado para a linha 335 (574 pontos). Progresso: 76/276\n",
      "2025-05-26 17:37:15,949 - INFO - SHAPE coletado para a linha 342 (654 pontos). Progresso: 77/276\n",
      "2025-05-26 17:37:15,976 - INFO - SHAPE coletado para a linha 343 (108 pontos). Progresso: 78/276\n",
      "2025-05-26 17:37:16,010 - INFO - SHAPE coletado para a linha 350 (602 pontos). Progresso: 79/276\n",
      "2025-05-26 17:37:16,059 - INFO - SHAPE coletado para a linha 345 (343 pontos). Progresso: 80/276\n",
      "2025-05-26 17:37:16,068 - INFO - SHAPE coletado para a linha 338 (1134 pontos). Progresso: 81/276\n",
      "2025-05-26 17:37:16,180 - INFO - SHAPE coletado para a linha 361 (694 pontos). Progresso: 82/276\n",
      "2025-05-26 17:37:16,206 - INFO - SHAPE coletado para a linha 360 (196 pontos). Progresso: 83/276\n",
      "2025-05-26 17:37:16,214 - INFO - SHAPE coletado para a linha 365 (829 pontos). Progresso: 84/276\n",
      "2025-05-26 17:37:16,342 - INFO - SHAPE coletado para a linha 371 (573 pontos). Progresso: 85/276\n",
      "2025-05-26 17:37:16,372 - INFO - SHAPE coletado para a linha 366 (400 pontos). Progresso: 86/276\n",
      "2025-05-26 17:37:16,414 - INFO - SHAPE coletado para a linha 374 (469 pontos). Progresso: 87/276\n",
      "2025-05-26 17:37:16,441 - INFO - SHAPE coletado para a linha 373 (384 pontos). Progresso: 88/276\n",
      "2025-05-26 17:37:16,444 - INFO - SHAPE coletado para a linha 372 (465 pontos). Progresso: 89/276\n",
      "2025-05-26 17:37:16,571 - INFO - SHAPE coletado para a linha 380 (583 pontos). Progresso: 90/276\n",
      "2025-05-26 17:37:16,610 - INFO - SHAPE coletado para a linha 375 (774 pontos). Progresso: 91/276\n",
      "2025-05-26 17:37:16,630 - INFO - SHAPE coletado para a linha 385 (364 pontos). Progresso: 92/276\n",
      "2025-05-26 17:37:16,663 - INFO - SHAPE coletado para a linha 386 (437 pontos). Progresso: 93/276\n",
      "2025-05-26 17:37:16,753 - INFO - SHAPE coletado para a linha 387 (763 pontos). Progresso: 94/276\n",
      "2025-05-26 17:37:16,846 - INFO - SHAPE coletado para a linha 389 (1287 pontos). Progresso: 95/276\n",
      "2025-05-26 17:37:16,889 - INFO - SHAPE coletado para a linha 461 (815 pontos). Progresso: 96/276\n",
      "2025-05-26 17:37:16,905 - INFO - SHAPE coletado para a linha 463 (696 pontos). Progresso: 97/276\n",
      "2025-05-26 17:37:16,992 - INFO - SHAPE coletado para a linha 462 (1762 pontos). Progresso: 98/276\n",
      "2025-05-26 17:37:17,059 - INFO - SHAPE coletado para a linha 464 (603 pontos). Progresso: 99/276\n",
      "2025-05-26 17:37:17,066 - INFO - SHAPE coletado para a linha 465 (569 pontos). Progresso: 100/276\n",
      "2025-05-26 17:37:17,221 - INFO - SHAPE coletado para a linha 468 (846 pontos). Progresso: 101/276\n",
      "2025-05-26 17:37:17,275 - INFO - SHAPE coletado para a linha 469 (573 pontos). Progresso: 102/276\n",
      "2025-05-26 17:37:17,318 - INFO - SHAPE coletado para a linha 471 (796 pontos). Progresso: 103/276\n",
      "2025-05-26 17:37:17,359 - INFO - SHAPE coletado para a linha 466 (1048 pontos). Progresso: 104/276\n",
      "2025-05-26 17:37:17,435 - INFO - SHAPE coletado para a linha 472 (921 pontos). Progresso: 105/276\n",
      "2025-05-26 17:37:17,625 - INFO - SHAPE coletado para a linha 474 (884 pontos). Progresso: 106/276\n",
      "2025-05-26 17:37:17,715 - INFO - SHAPE coletado para a linha 475 (906 pontos). Progresso: 107/276\n",
      "2025-05-26 17:37:17,774 - INFO - SHAPE coletado para a linha 489 (810 pontos). Progresso: 108/276\n",
      "2025-05-26 17:37:17,900 - INFO - SHAPE coletado para a linha 477 (896 pontos). Progresso: 109/276\n",
      "2025-05-26 17:37:18,051 - INFO - SHAPE coletado para a linha 503 (693 pontos). Progresso: 110/276\n",
      "2025-05-26 17:37:18,090 - INFO - SHAPE coletado para a linha 500 (1932 pontos). Progresso: 111/276\n",
      "2025-05-26 17:37:18,280 - INFO - SHAPE coletado para a linha 505 (866 pontos). Progresso: 112/276\n",
      "2025-05-26 17:37:18,435 - INFO - SHAPE coletado para a linha 506 (1272 pontos). Progresso: 113/276\n",
      "2025-05-26 17:37:18,471 - INFO - SHAPE coletado para a linha 508 (775 pontos). Progresso: 114/276\n",
      "2025-05-26 17:37:18,476 - INFO - SHAPE coletado para a linha 509 (499 pontos). Progresso: 115/276\n",
      "2025-05-26 17:37:18,562 - INFO - Nenhum SHAPE válido para linha 511. Progresso: 116/276\n",
      "2025-05-26 17:37:18,567 - INFO - SHAPE coletado para a linha 507 (4486 pontos). Progresso: 117/276\n",
      "2025-05-26 17:37:18,659 - INFO - SHAPE coletado para a linha 513 (470 pontos). Progresso: 118/276\n",
      "2025-05-26 17:37:18,664 - INFO - SHAPE coletado para a linha 512 (436 pontos). Progresso: 119/276\n",
      "2025-05-26 17:37:18,700 - INFO - SHAPE coletado para a linha 502 (6187 pontos). Progresso: 120/276\n",
      "2025-05-26 17:37:18,763 - INFO - SHAPE coletado para a linha 516 (274 pontos). Progresso: 121/276\n",
      "2025-05-26 17:37:18,790 - INFO - SHAPE coletado para a linha 515 (446 pontos). Progresso: 122/276\n",
      "2025-05-26 17:37:18,860 - INFO - SHAPE coletado para a linha 521 (216 pontos). Progresso: 123/276\n",
      "2025-05-26 17:37:18,892 - INFO - SHAPE coletado para a linha 518 (273 pontos). Progresso: 124/276\n",
      "2025-05-26 17:37:18,935 - INFO - SHAPE coletado para a linha 522 (401 pontos). Progresso: 125/276\n",
      "2025-05-26 17:37:18,948 - INFO - SHAPE coletado para a linha 519 (586 pontos). Progresso: 126/276\n",
      "2025-05-26 17:37:19,004 - INFO - SHAPE coletado para a linha 523 (162 pontos). Progresso: 127/276\n",
      "2025-05-26 17:37:19,107 - INFO - SHAPE coletado para a linha 524 (476 pontos). Progresso: 128/276\n",
      "2025-05-26 17:37:19,148 - INFO - SHAPE coletado para a linha 528 (1138 pontos). Progresso: 129/276\n",
      "2025-05-26 17:37:19,154 - INFO - SHAPE coletado para a linha 529 (120 pontos). Progresso: 130/276\n",
      "2025-05-26 17:37:19,165 - INFO - SHAPE coletado para a linha 531 (456 pontos). Progresso: 131/276\n",
      "2025-05-26 17:37:19,192 - INFO - SHAPE coletado para a linha 532 (303 pontos). Progresso: 132/276\n",
      "2025-05-26 17:37:19,365 - INFO - SHAPE coletado para a linha 536 (524 pontos). Progresso: 133/276\n",
      "2025-05-26 17:37:19,373 - INFO - SHAPE coletado para a linha 541 (319 pontos). Progresso: 134/276\n",
      "2025-05-26 17:37:19,382 - INFO - SHAPE coletado para a linha 534 (394 pontos). Progresso: 135/276\n",
      "2025-05-26 17:37:19,393 - INFO - SHAPE coletado para a linha 535 (561 pontos). Progresso: 136/276\n",
      "2025-05-26 17:37:19,402 - INFO - SHAPE coletado para a linha 533 (654 pontos). Progresso: 137/276\n",
      "2025-05-26 17:37:19,577 - INFO - SHAPE coletado para a linha 547 (324 pontos). Progresso: 138/276\n",
      "2025-05-26 17:37:19,610 - INFO - SHAPE coletado para a linha 549 (446 pontos). Progresso: 139/276\n",
      "2025-05-26 17:37:19,620 - INFO - SHAPE coletado para a linha 542 (316 pontos). Progresso: 140/276\n",
      "2025-05-26 17:37:19,674 - INFO - SHAPE coletado para a linha 548 (749 pontos). Progresso: 141/276\n",
      "2025-05-26 17:37:19,704 - INFO - SHAPE coletado para a linha 545 (1307 pontos). Progresso: 142/276\n",
      "2025-05-26 17:37:19,779 - INFO - SHAPE coletado para a linha 553 (284 pontos). Progresso: 143/276\n",
      "2025-05-26 17:37:19,821 - INFO - SHAPE coletado para a linha 550 (1163 pontos). Progresso: 144/276\n",
      "2025-05-26 17:37:19,876 - INFO - SHAPE coletado para a linha 552 (468 pontos). Progresso: 145/276\n",
      "2025-05-26 17:37:19,896 - INFO - SHAPE coletado para a linha 561 (358 pontos). Progresso: 146/276\n",
      "2025-05-26 17:37:19,931 - INFO - SHAPE coletado para a linha 560 (339 pontos). Progresso: 147/276\n",
      "2025-05-26 17:37:20,227 - INFO - SHAPE coletado para a linha 603 (649 pontos). Progresso: 148/276\n",
      "2025-05-26 17:37:20,257 - INFO - SHAPE coletado para a linha 609 (346 pontos). Progresso: 149/276\n",
      "2025-05-26 17:37:20,342 - INFO - SHAPE coletado para a linha 607 (1688 pontos). Progresso: 150/276\n",
      "2025-05-26 17:37:20,433 - INFO - SHAPE coletado para a linha 612 (458 pontos). Progresso: 151/276\n",
      "2025-05-26 17:37:20,494 - INFO - SHAPE coletado para a linha 602 (4471 pontos). Progresso: 152/276\n",
      "2025-05-26 17:37:20,503 - INFO - SHAPE coletado para a linha 611 (410 pontos). Progresso: 153/276\n",
      "2025-05-26 17:37:20,617 - INFO - SHAPE coletado para a linha 615 (242 pontos). Progresso: 154/276\n",
      "2025-05-26 17:37:20,763 - INFO - SHAPE coletado para a linha 616 (690 pontos). Progresso: 155/276\n",
      "2025-05-26 17:37:20,941 - INFO - SHAPE coletado para a linha 617 (916 pontos). Progresso: 156/276\n",
      "2025-05-26 17:37:20,959 - INFO - SHAPE coletado para a linha 619 (999 pontos). Progresso: 157/276\n",
      "2025-05-26 17:37:21,002 - INFO - SHAPE coletado para a linha 622 (349 pontos). Progresso: 158/276\n",
      "2025-05-26 17:37:21,009 - INFO - SHAPE coletado para a linha 621 (428 pontos). Progresso: 159/276\n",
      "2025-05-26 17:37:21,060 - INFO - SHAPE coletado para a linha 600 (961 pontos). Progresso: 160/276\n",
      "2025-05-26 17:37:21,183 - INFO - SHAPE coletado para a linha 623 (420 pontos). Progresso: 161/276\n",
      "2025-05-26 17:37:21,226 - INFO - SHAPE coletado para a linha 624 (415 pontos). Progresso: 162/276\n",
      "2025-05-26 17:37:21,290 - INFO - SHAPE coletado para a linha 628 (1106 pontos). Progresso: 163/276\n",
      "2025-05-26 17:37:21,342 - INFO - SHAPE coletado para a linha 629 (795 pontos). Progresso: 164/276\n",
      "2025-05-26 17:37:21,348 - INFO - SHAPE coletado para a linha 625 (551 pontos). Progresso: 165/276\n",
      "2025-05-26 17:37:21,383 - INFO - SHAPE coletado para a linha 627 (947 pontos). Progresso: 166/276\n",
      "2025-05-26 17:37:21,392 - INFO - SHAPE coletado para a linha 630 (819 pontos). Progresso: 167/276\n",
      "2025-05-26 17:37:21,461 - INFO - SHAPE coletado para a linha 631 (405 pontos). Progresso: 168/276\n",
      "2025-05-26 17:37:21,548 - INFO - SHAPE coletado para a linha 632 (245 pontos). Progresso: 169/276\n",
      "2025-05-26 17:37:21,554 - INFO - SHAPE coletado para a linha 633 (400 pontos). Progresso: 170/276\n",
      "2025-05-26 17:37:21,583 - INFO - SHAPE coletado para a linha 636 (384 pontos). Progresso: 171/276\n",
      "2025-05-26 17:37:21,585 - INFO - SHAPE coletado para a linha 635 (373 pontos). Progresso: 172/276\n",
      "2025-05-26 17:37:21,647 - INFO - SHAPE coletado para a linha 637 (464 pontos). Progresso: 173/276\n",
      "2025-05-26 17:37:21,738 - INFO - SHAPE coletado para a linha 640 (461 pontos). Progresso: 174/276\n",
      "2025-05-26 17:37:21,756 - INFO - SHAPE coletado para a linha 638 (531 pontos). Progresso: 175/276\n",
      "2025-05-26 17:37:21,771 - INFO - SHAPE coletado para a linha 639 (551 pontos). Progresso: 176/276\n",
      "2025-05-26 17:37:21,816 - INFO - SHAPE coletado para a linha 641 (1009 pontos). Progresso: 177/276\n",
      "2025-05-26 17:37:21,848 - INFO - SHAPE coletado para a linha 642 (937 pontos). Progresso: 178/276\n",
      "2025-05-26 17:37:21,946 - INFO - SHAPE coletado para a linha 643 (1728 pontos). Progresso: 179/276\n",
      "2025-05-26 17:37:21,951 - INFO - SHAPE coletado para a linha 644 (598 pontos). Progresso: 180/276\n",
      "2025-05-26 17:37:21,999 - INFO - SHAPE coletado para a linha 649 (378 pontos). Progresso: 181/276\n",
      "2025-05-26 17:37:22,064 - INFO - SHAPE coletado para a linha 646 (1548 pontos). Progresso: 182/276\n",
      "2025-05-26 17:37:22,193 - INFO - SHAPE coletado para a linha 652 (669 pontos). Progresso: 183/276\n",
      "2025-05-26 17:37:22,206 - INFO - SHAPE coletado para a linha 654 (502 pontos). Progresso: 184/276\n",
      "2025-05-26 17:37:22,208 - INFO - SHAPE coletado para a linha 653 (636 pontos). Progresso: 185/276\n",
      "2025-05-26 17:37:22,222 - INFO - SHAPE coletado para a linha 650 (1599 pontos). Progresso: 186/276\n",
      "2025-05-26 17:37:22,310 - INFO - SHAPE coletado para a linha 655 (1156 pontos). Progresso: 187/276\n",
      "2025-05-26 17:37:22,336 - INFO - Nenhum SHAPE válido para linha 657. Progresso: 188/276\n",
      "2025-05-26 17:37:22,458 - INFO - SHAPE coletado para a linha 658 (845 pontos). Progresso: 189/276\n",
      "2025-05-26 17:37:22,464 - INFO - SHAPE coletado para a linha 661 (537 pontos). Progresso: 190/276\n",
      "2025-05-26 17:37:22,509 - INFO - SHAPE coletado para a linha 662 (482 pontos). Progresso: 191/276\n",
      "2025-05-26 17:37:22,523 - INFO - SHAPE coletado para a linha 659 (1543 pontos). Progresso: 192/276\n",
      "2025-05-26 17:37:22,620 - INFO - SHAPE coletado para a linha 663 (874 pontos). Progresso: 193/276\n",
      "2025-05-26 17:37:22,682 - INFO - SHAPE coletado para a linha 665 (824 pontos). Progresso: 194/276\n",
      "2025-05-26 17:37:22,739 - INFO - SHAPE coletado para a linha 670 (677 pontos). Progresso: 195/276\n",
      "2025-05-26 17:37:22,834 - INFO - SHAPE coletado para a linha 668 (1024 pontos). Progresso: 196/276\n",
      "2025-05-26 17:37:22,886 - INFO - SHAPE coletado para a linha 671 (591 pontos). Progresso: 197/276\n",
      "2025-05-26 17:37:22,904 - INFO - SHAPE coletado para a linha 673 (616 pontos). Progresso: 198/276\n",
      "2025-05-26 17:37:22,958 - INFO - SHAPE coletado para a linha 674 (828 pontos). Progresso: 199/276\n",
      "2025-05-26 17:37:23,133 - INFO - SHAPE coletado para a linha 679 (1715 pontos). Progresso: 200/276\n",
      "2025-05-26 17:37:23,143 - INFO - SHAPE coletado para a linha 680 (1041 pontos). Progresso: 201/276\n",
      "2025-05-26 17:37:23,220 - INFO - SHAPE coletado para a linha 681 (916 pontos). Progresso: 202/276\n",
      "2025-05-26 17:37:23,295 - INFO - SHAPE coletado para a linha 683 (924 pontos). Progresso: 203/276\n",
      "2025-05-26 17:37:23,385 - INFO - SHAPE coletado para a linha 685 (1143 pontos). Progresso: 204/276\n",
      "2025-05-26 17:37:23,461 - INFO - SHAPE coletado para a linha 684 (1588 pontos). Progresso: 205/276\n",
      "2025-05-26 17:37:23,523 - INFO - SHAPE coletado para a linha 689 (965 pontos). Progresso: 206/276\n",
      "2025-05-26 17:37:23,735 - INFO - SHAPE coletado para a linha 701 (756 pontos). Progresso: 207/276\n",
      "2025-05-26 17:37:23,824 - INFO - SHAPE coletado para a linha 666 (726 pontos). Progresso: 208/276\n",
      "2025-05-26 17:37:23,826 - INFO - SHAPE coletado para a linha 703 (964 pontos). Progresso: 209/276\n",
      "2025-05-26 17:37:23,913 - INFO - SHAPE coletado para a linha 700 (1222 pontos). Progresso: 210/276\n",
      "2025-05-26 17:37:23,954 - INFO - SHAPE coletado para a linha 702 (1904 pontos). Progresso: 211/276\n",
      "2025-05-26 17:37:24,064 - INFO - SHAPE coletado para a linha 710 (403 pontos). Progresso: 212/276\n",
      "2025-05-26 17:37:24,113 - INFO - SHAPE coletado para a linha 707 (678 pontos). Progresso: 213/276\n",
      "2025-05-26 17:37:24,157 - INFO - SHAPE coletado para a linha 711 (354 pontos). Progresso: 214/276\n",
      "2025-05-26 17:37:24,167 - INFO - SHAPE coletado para a linha 706 (1601 pontos). Progresso: 215/276\n",
      "2025-05-26 17:37:24,218 - INFO - SHAPE coletado para a linha 712 (497 pontos). Progresso: 216/276\n",
      "2025-05-26 17:37:24,238 - INFO - SHAPE coletado para a linha 713 (238 pontos). Progresso: 217/276\n",
      "2025-05-26 17:37:24,313 - INFO - SHAPE coletado para a linha 718 (271 pontos). Progresso: 218/276\n",
      "2025-05-26 17:37:24,337 - INFO - SHAPE coletado para a linha 722 (244 pontos). Progresso: 219/276\n",
      "2025-05-26 17:37:24,370 - INFO - SHAPE coletado para a linha 723 (243 pontos). Progresso: 220/276\n",
      "2025-05-26 17:37:24,380 - INFO - SHAPE coletado para a linha 721 (636 pontos). Progresso: 221/276\n",
      "2025-05-26 17:37:24,420 - INFO - SHAPE coletado para a linha 724 (343 pontos). Progresso: 222/276\n",
      "2025-05-26 17:37:24,489 - INFO - SHAPE coletado para a linha 760 (474 pontos). Progresso: 223/276\n",
      "2025-05-26 17:37:24,564 - INFO - SHAPE coletado para a linha 761 (852 pontos). Progresso: 224/276\n",
      "2025-05-26 17:37:24,607 - INFO - SHAPE coletado para a linha 762 (877 pontos). Progresso: 225/276\n",
      "2025-05-26 17:37:24,678 - INFO - SHAPE coletado para a linha 772 (1430 pontos). Progresso: 226/276\n",
      "2025-05-26 17:37:24,710 - INFO - SHAPE coletado para a linha 773 (968 pontos). Progresso: 227/276\n",
      "2025-05-26 17:37:24,716 - INFO - SHAPE coletado para a linha 777 (601 pontos). Progresso: 228/276\n",
      "2025-05-26 17:37:24,763 - INFO - SHAPE coletado para a linha 778 (966 pontos). Progresso: 229/276\n",
      "2025-05-26 17:37:24,803 - INFO - SHAPE coletado para a linha 779 (460 pontos). Progresso: 230/276\n",
      "2025-05-26 17:37:24,873 - INFO - SHAPE coletado para a linha 788 (875 pontos). Progresso: 231/276\n",
      "2025-05-26 17:37:24,911 - INFO - SHAPE coletado para a linha 789 (965 pontos). Progresso: 232/276\n",
      "2025-05-26 17:37:24,934 - INFO - SHAPE coletado para a linha 794 (384 pontos). Progresso: 233/276\n",
      "2025-05-26 17:37:24,955 - INFO - SHAPE coletado para a linha 801 (363 pontos). Progresso: 234/276\n",
      "2025-05-26 17:37:24,998 - INFO - SHAPE coletado para a linha 809 (656 pontos). Progresso: 235/276\n",
      "2025-05-26 17:37:25,070 - INFO - SHAPE coletado para a linha 812 (874 pontos). Progresso: 236/276\n",
      "2025-05-26 17:37:25,116 - INFO - SHAPE coletado para a linha 814 (558 pontos). Progresso: 237/276\n",
      "2025-05-26 17:37:25,161 - INFO - SHAPE coletado para a linha 816 (716 pontos). Progresso: 238/276\n",
      "2025-05-26 17:37:25,207 - INFO - SHAPE coletado para a linha 817 (886 pontos). Progresso: 239/276\n",
      "2025-05-26 17:37:25,263 - INFO - SHAPE coletado para a linha 822 (101 pontos). Progresso: 240/276\n",
      "2025-05-26 17:37:25,281 - INFO - SHAPE coletado para a linha 820 (1294 pontos). Progresso: 241/276\n",
      "2025-05-26 17:37:25,321 - INFO - SHAPE coletado para a linha 821 (991 pontos). Progresso: 242/276\n",
      "2025-05-26 17:37:25,363 - INFO - SHAPE coletado para a linha 823 (820 pontos). Progresso: 243/276\n",
      "2025-05-26 17:37:25,489 - INFO - SHAPE coletado para a linha 827 (648 pontos). Progresso: 244/276\n",
      "2025-05-26 17:37:25,514 - INFO - SHAPE coletado para a linha 829 (481 pontos). Progresso: 245/276\n",
      "2025-05-26 17:37:25,646 - INFO - SHAPE coletado para a linha 832 (315 pontos). Progresso: 246/276\n",
      "2025-05-26 17:37:25,672 - INFO - SHAPE coletado para a linha 825 (947 pontos). Progresso: 247/276\n",
      "2025-05-26 17:37:25,695 - INFO - SHAPE coletado para a linha 826 (1067 pontos). Progresso: 248/276\n",
      "2025-05-26 17:37:25,720 - INFO - SHAPE coletado para a linha 828 (1091 pontos). Progresso: 249/276\n",
      "2025-05-26 17:37:25,845 - INFO - SHAPE coletado para a linha 860 (1341 pontos). Progresso: 250/276\n",
      "2025-05-26 17:37:25,857 - INFO - SHAPE coletado para a linha 861 (951 pontos). Progresso: 251/276\n",
      "2025-05-26 17:37:25,877 - INFO - SHAPE coletado para a linha 863 (363 pontos). Progresso: 252/276\n",
      "2025-05-26 17:37:25,894 - INFO - SHAPE coletado para a linha 862 (670 pontos). Progresso: 253/276\n",
      "2025-05-26 17:37:25,925 - INFO - SHAPE coletado para a linha 864 (919 pontos). Progresso: 254/276\n",
      "2025-05-26 17:37:26,018 - INFO - SHAPE coletado para a linha 865 (657 pontos). Progresso: 255/276\n",
      "2025-05-26 17:37:26,079 - INFO - SHAPE coletado para a linha 870 (838 pontos). Progresso: 256/276\n",
      "2025-05-26 17:37:26,098 - INFO - SHAPE coletado para a linha 875 (645 pontos). Progresso: 257/276\n",
      "2025-05-26 17:37:26,170 - INFO - SHAPE coletado para a linha 876 (1206 pontos). Progresso: 258/276\n",
      "2025-05-26 17:37:26,183 - INFO - SHAPE coletado para a linha 889 (722 pontos). Progresso: 259/276\n",
      "2025-05-26 17:37:26,311 - INFO - SHAPE coletado para a linha 911 (725 pontos). Progresso: 260/276\n",
      "2025-05-26 17:37:26,339 - INFO - SHAPE coletado para a linha 901 (703 pontos). Progresso: 261/276\n",
      "2025-05-26 17:37:26,386 - INFO - SHAPE coletado para a linha 902 (651 pontos). Progresso: 262/276\n",
      "2025-05-26 17:37:26,514 - INFO - SHAPE coletado para a linha 912 (413 pontos). Progresso: 263/276\n",
      "2025-05-26 17:37:26,549 - INFO - SHAPE coletado para a linha 913 (850 pontos). Progresso: 264/276\n",
      "2025-05-26 17:37:26,567 - INFO - SHAPE coletado para a linha 916 (339 pontos). Progresso: 265/276\n",
      "2025-05-26 17:37:26,667 - INFO - SHAPE coletado para a linha 917 (407 pontos). Progresso: 266/276\n",
      "2025-05-26 17:37:26,875 - INFO - SHAPE coletado para a linha 915 (1190 pontos). Progresso: 267/276\n",
      "2025-05-26 17:37:26,939 - INFO - SHAPE coletado para a linha 958 (439 pontos). Progresso: 268/276\n",
      "2025-05-26 17:37:26,987 - INFO - SHAPE coletado para a linha 948 (1158 pontos). Progresso: 269/276\n",
      "2025-05-26 17:37:27,063 - INFO - SHAPE coletado para a linha 928 (1595 pontos). Progresso: 270/276\n",
      "2025-05-26 17:37:27,075 - INFO - SHAPE coletado para a linha 924 (1942 pontos). Progresso: 271/276\n",
      "2025-05-26 17:37:27,231 - INFO - SHAPE coletado para a linha 965 (1058 pontos). Progresso: 272/276\n",
      "2025-05-26 17:37:27,240 - INFO - SHAPE coletado para a linha 967 (712 pontos). Progresso: 273/276\n",
      "2025-05-26 17:37:27,259 - INFO - SHAPE coletado para a linha 972 (917 pontos). Progresso: 274/276\n",
      "2025-05-26 17:37:27,316 - INFO - SHAPE coletado para a linha 989 (1057 pontos). Progresso: 275/276\n",
      "2025-05-26 17:37:27,393 - INFO - SHAPE coletado para a linha 979 (3011 pontos). Progresso: 276/276\n",
      "2025-05-26 17:37:27,420 - INFO - Total de 210879 pontos de SHAPE coletados de todas as linhas com threads (antes da remoção de duplicatas).\n",
      "2025-05-26 17:37:27,489 - INFO - Remoção de duplicatas (pontos de SHAPE idênticos): 1 registros duplicados removidos.\n",
      "2025-05-26 17:37:27,489 - INFO - Número final de registros de SHAPE únicos: 210878\n",
      "2025-05-26 17:37:27,490 - INFO - Amostra dos dados finais de SHAPE coletados e processados (DataFrame 'df_todos_os_shapes'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SHP   Latitude  Longitude  COD\n",
      "0  4091 -25.492281 -49.293103  020\n",
      "1  4091 -25.491527 -49.293194  020\n",
      "2  4091 -25.491572 -49.293684  020\n",
      "3  4091 -25.491621 -49.293843  020\n",
      "4  4091 -25.491644 -49.295450  020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 17:37:28,366 - INFO - DataFrame de SHAPES consolidado e limpo salvo em: 'dados_shapes_onibus_urbs_consolidado_threads.csv'\n",
      "2025-05-26 17:37:28,366 - INFO - Processamento de SHAPES finalizado.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time \n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Configuração de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Número máximo de requisições concorrentes (threads)\n",
    "MAX_CONCURRENT_REQUESTS = 5 # Ajuste conforme necessário (5-10 é um bom começo)\n",
    "\n",
    "def buscar_e_processar_shape_linha(codigo_linha_str):\n",
    "    \"\"\"\n",
    "    Busca os dados do shape (trajeto) de uma linha de ônibus específica da API da URBS.\n",
    "    O codigo_linha_str deve ser uma string (ex: \"010\", \"203\", \"666\").\n",
    "    Retorna um DataFrame com colunas: SHP, Latitude, Longitude, COD.\n",
    "    \"\"\"\n",
    "    codigo_linha_formatado = codigo_linha_str.zfill(3)\n",
    "    url = f'https://transporteservico.urbs.curitiba.pr.gov.br/getShapeLinha.php?linha={codigo_linha_formatado}&c=821f0'\n",
    "    try:\n",
    "        response = requests.get(url, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        dados_json = response.json()\n",
    "\n",
    "        if not dados_json:\n",
    "            # logging.info(f\"Nenhum dado JSON de SHAPE retornado para a linha {codigo_linha_str}.\")\n",
    "            return None\n",
    "        \n",
    "        if not isinstance(dados_json, list) or not all(isinstance(item, dict) for item in dados_json):\n",
    "            logging.warning(f\"Formato de dados de SHAPE inesperado para a linha {codigo_linha_str}. Dados: {str(dados_json)[:200]}...\")\n",
    "            return None\n",
    "        \n",
    "        if not dados_json: # Segurança extra\n",
    "             return None\n",
    "\n",
    "        df = pd.DataFrame.from_records(dados_json)\n",
    "\n",
    "        # Colunas esperadas da API getShapeLinha\n",
    "        required_cols_from_api = {'SHP', 'LAT', 'LON'} \n",
    "        if not required_cols_from_api.issubset(df.columns):\n",
    "            # A API getShapeLinha também retorna 'COD' no JSON, mas vamos adicionar o nosso para consistência\n",
    "            # Se a API retornar COD, podemos usá-lo ou compará-lo. Por agora, vamos focar em SHP, LAT, LON.\n",
    "            # Se a API retornar COD, a linha abaixo pode ser ajustada.\n",
    "            # O exemplo fornecido na pergunta mostra que a API retorna COD, então vamos incluir.\n",
    "            if 'COD' in df.columns: # Se a API já retorna COD, ótimo.\n",
    "                required_cols_from_api.add('COD') # Adiciona à verificação\n",
    "            \n",
    "            if not required_cols_from_api.issubset(df.columns):\n",
    "                 logging.warning(f\"Colunas de SHAPE esperadas ('SHP', 'LAT', 'LON') ausentes da API para a linha {codigo_linha_str}. Colunas recebidas: {df.columns.tolist()}.\")\n",
    "                 return None\n",
    "\n",
    "\n",
    "        df['Latitude'] = df['LAT'].str.replace(',', '.').astype(float)\n",
    "        df['Longitude'] = df['LON'].str.replace(',', '.').astype(float)\n",
    "        \n",
    "        # A API getShapeLinha já retorna uma coluna 'COD' no JSON.\n",
    "        # Vamos garantir que ela exista e seja do tipo string para consistência.\n",
    "        if 'COD' in df.columns:\n",
    "            df['COD'] = df['COD'].astype(str)\n",
    "        else:\n",
    "            # Se a API não retornar COD (improvável baseado no exemplo), adicionamos o que usamos na busca\n",
    "            df['COD'] = codigo_linha_str\n",
    "        \n",
    "        # Garante que SHP seja string\n",
    "        if 'SHP' in df.columns:\n",
    "            df['SHP'] = df['SHP'].astype(str)\n",
    "        else: # Caso SHP não venha, o que seria um erro da API para esta chamada\n",
    "            logging.error(f\"Coluna 'SHP' ausente nos dados da API para a linha {codigo_linha_str}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "        colunas_desejadas = ['SHP', 'Latitude', 'Longitude', 'COD']\n",
    "        return df[colunas_desejadas]\n",
    "\n",
    "    except requests.exceptions.JSONDecodeError:\n",
    "        logging.error(f\"Erro ao decodificar JSON de SHAPE para a linha {codigo_linha_str}. URL: {url}. Resposta: {response.text[:200]}...\")\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logging.warning(f\"Erro HTTP {http_err.response.status_code} para SHAPE da linha {codigo_linha_str} (URL: {url}).\")\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Erro na requisição de SHAPE para a linha {codigo_linha_str} (URL: {url}): {e}\")\n",
    "    except KeyError as e: \n",
    "        logging.error(f\"Coluna esperada não encontrada ao processar SHAPE da linha {codigo_linha_str}: {e}. Dados: {dados_json if 'dados_json' in locals() else 'N/A'}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro inesperado ao processar SHAPE da linha {codigo_linha_str} (URL: {url}): {e}\", exc_info=False)\n",
    "    return None\n",
    "\n",
    "def coletar_shapes_de_todas_as_linhas_com_threads(lista_codigos_linhas, max_workers=MAX_CONCURRENT_REQUESTS):\n",
    "    \"\"\"\n",
    "    Coleta dados de SHAPE de todas as linhas de ônibus fornecidas na lista usando threads.\n",
    "    Retorna um DataFrame único com todos os dados ou um DataFrame vazio.\n",
    "    \"\"\"\n",
    "    todos_os_shapes_coletados_dfs = []\n",
    "    logging.info(f\"Iniciando coleta de SHAPES com até {max_workers} threads para {len(lista_codigos_linhas)} linhas únicas.\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_linha = {executor.submit(buscar_e_processar_shape_linha, codigo_linha): codigo_linha for codigo_linha in lista_codigos_linhas}\n",
    "        \n",
    "        processed_count = 0\n",
    "        for future in as_completed(future_to_linha):\n",
    "            codigo_linha = future_to_linha[future]\n",
    "            processed_count += 1\n",
    "            try:\n",
    "                df_shape_da_linha = future.result()\n",
    "                if df_shape_da_linha is not None and not df_shape_da_linha.empty:\n",
    "                    todos_os_shapes_coletados_dfs.append(df_shape_da_linha)\n",
    "                    logging.info(f\"SHAPE coletado para a linha {codigo_linha} ({len(df_shape_da_linha)} pontos). Progresso: {processed_count}/{len(lista_codigos_linhas)}\")\n",
    "                else:\n",
    "                    logging.info(f\"Nenhum SHAPE válido para linha {codigo_linha}. Progresso: {processed_count}/{len(lista_codigos_linhas)}\")\n",
    "            except Exception as exc:\n",
    "                logging.error(f\"Linha {codigo_linha} (SHAPE) gerou uma exceção ao obter resultado da thread: {exc}\", exc_info=False)\n",
    "                logging.info(f\"Progresso: {processed_count}/{len(lista_codigos_linhas)}\")\n",
    "\n",
    "    if not todos_os_shapes_coletados_dfs:\n",
    "        logging.warning(\"Nenhum SHAPE foi coletado de nenhuma das linhas especificadas usando threads.\")\n",
    "        return pd.DataFrame() \n",
    "\n",
    "    df_consolidado = pd.concat(todos_os_shapes_coletados_dfs, ignore_index=True)\n",
    "    logging.info(f\"Total de {len(df_consolidado)} pontos de SHAPE coletados de todas as linhas com threads (antes da remoção de duplicatas).\")\n",
    "    \n",
    "    return df_consolidado\n",
    "\n",
    "def iniciar_coleta_shapes_para_dataframe(caminho_arquivo_csv_linhas):\n",
    "    logging.info(f\"Iniciando processo de coleta de SHAPES a partir do arquivo: {caminho_arquivo_csv_linhas}\")\n",
    "    try:\n",
    "        df_arquivo_linhas = pd.read_csv(caminho_arquivo_csv_linhas)\n",
    "        \n",
    "        if 'COD_Linha' not in df_arquivo_linhas.columns:\n",
    "            logging.error(f\"A coluna 'COD_Linha' não foi encontrada no arquivo CSV: {caminho_arquivo_csv_linhas}.\")\n",
    "            return\n",
    "        \n",
    "        # Converte para string para garantir que \"010\" seja tratado como string\n",
    "        linhas_unicas_para_coleta = df_arquivo_linhas['COD_Linha'].astype(str).unique().tolist()\n",
    "        \n",
    "        if not linhas_unicas_para_coleta:\n",
    "            logging.warning(\"Nenhum código de linha único para processar encontrado no arquivo CSV.\")\n",
    "            return\n",
    "\n",
    "        logging.info(f\"Encontrados {len(linhas_unicas_para_coleta)} códigos de linha únicos para processamento de SHAPES: {linhas_unicas_para_coleta[:10]}... (mostrando até 10)\")\n",
    "\n",
    "        df_todos_os_shapes = coletar_shapes_de_todas_as_linhas_com_threads(linhas_unicas_para_coleta)\n",
    "\n",
    "        if df_todos_os_shapes.empty:\n",
    "            logging.info(\"Nenhum SHAPE foi coletado após processar todas as linhas com threads. Encerrando.\")\n",
    "            return\n",
    "\n",
    "        registros_antes_dedup = len(df_todos_os_shapes)\n",
    "        # Para shapes, cada ponto é definido por COD, SHP, Latitude, Longitude.\n",
    "        # A ordem dos pontos dentro de um SHP é importante e deve ser preservada pela API.\n",
    "        # drop_duplicates aqui removeria pontos idênticos se existirem.\n",
    "        df_todos_os_shapes.drop_duplicates(subset=['COD', 'SHP', 'Latitude', 'Longitude'], keep='first', inplace=True)\n",
    "        registros_depois_dedup = len(df_todos_os_shapes)\n",
    "        logging.info(f\"Remoção de duplicatas (pontos de SHAPE idênticos): {registros_antes_dedup - registros_depois_dedup} registros duplicados removidos.\")\n",
    "        logging.info(f\"Número final de registros de SHAPE únicos: {registros_depois_dedup}\")\n",
    "\n",
    "        logging.info(\"Amostra dos dados finais de SHAPE coletados e processados (DataFrame 'df_todos_os_shapes'):\")\n",
    "        print(df_todos_os_shapes.head())\n",
    "        \n",
    "        nome_arquivo_saida = \"dados_shapes_onibus_urbs_consolidado_threads.csv\"\n",
    "        df_todos_os_shapes.to_csv(nome_arquivo_saida, index=False, encoding='utf-8-sig')\n",
    "        logging.info(f\"DataFrame de SHAPES consolidado e limpo salvo em: '{nome_arquivo_saida}'\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Arquivo de linhas não encontrado em: {caminho_arquivo_csv_linhas}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logging.error(f\"O arquivo CSV de linhas ({caminho_arquivo_csv_linhas}) está vazio ou mal formatado.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Um erro geral ocorreu durante o processamento de SHAPES: {e}\", exc_info=True)\n",
    "    finally:\n",
    "        logging.info(\"Processamento de SHAPES finalizado.\")\n",
    "\n",
    "# --- Para Executar o Script ---\n",
    "if __name__ == '__main__':\n",
    "    # Certifique-se que o arquivo Linha.csv está no mesmo diretório\n",
    "    # ou forneça o caminho completo.\n",
    "    # A coluna com os códigos das linhas no CSV deve se chamar 'COD_Linha'.\n",
    "    caminho_do_arquivo_csv_com_linhas = 'Linha.csv' \n",
    "    \n",
    "    iniciar_coleta_shapes_para_dataframe(caminho_do_arquivo_csv_com_linhas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f788cd-4680-4227-820d-3e01de10440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_pontos_rota = pd.read_csv('dados_shapes_onibus_urbs_consolidado_threads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71c71626-8a39-4fd9-a3de-137ec6df9751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20,  11,  10,  22,  21,  23,  60,  30,  50,  40, 150, 164, 160,\n",
       "       166, 168, 169, 170, 171, 175, 176, 177, 182, 183, 184, 189, 203,\n",
       "       181, 188, 207, 205, 211, 212, 210, 213, 214, 206, 224, 222, 226,\n",
       "       225, 209, 216, 229, 231, 233, 236, 237, 238, 242, 232, 244, 243,\n",
       "       260, 266, 245, 265, 250, 272, 274, 303, 280, 275, 304, 305, 308,\n",
       "       307, 309, 311, 322, 323, 321, 331, 332, 334, 336, 335, 342, 343,\n",
       "       350, 345, 338, 361, 360, 365, 371, 366, 374, 373, 372, 380, 375,\n",
       "       385, 386, 387, 389, 461, 463, 462, 464, 465, 468, 469, 471, 466,\n",
       "       472, 474, 475, 489, 477, 503, 500, 505, 506, 508, 509, 507, 513,\n",
       "       512, 502, 516, 515, 521, 518, 522, 519, 523, 524, 528, 529, 531,\n",
       "       532, 536, 541, 534, 535, 533, 547, 549, 542, 548, 545, 553, 550,\n",
       "       552, 561, 560, 603, 609, 607, 612, 602, 611, 615, 616, 617, 619,\n",
       "       622, 621, 600, 623, 624, 628, 629, 625, 627, 630, 631, 632, 633,\n",
       "       636, 635, 637, 640, 638, 639, 641, 642, 643, 644, 649, 646, 652,\n",
       "       654, 653, 650, 655, 658, 661, 662, 659, 663, 665, 670, 668, 671,\n",
       "       673, 674, 679, 680, 681, 683, 685, 684, 689, 701, 666, 703, 700,\n",
       "       702, 710, 707, 711, 706, 712, 713, 718, 722, 723, 721, 724, 760,\n",
       "       761, 762, 772, 773, 777, 778, 779, 788, 789, 794, 801, 809, 812,\n",
       "       814, 816, 817, 822, 820, 821, 823, 827, 829, 832, 825, 826, 828,\n",
       "       860, 861, 863, 862, 864, 865, 870, 875, 876, 889, 911, 901, 902,\n",
       "       912, 913, 916, 917, 915, 958, 948, 928, 924, 965, 967, 972, 989,\n",
       "       979])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pontos_rota['COD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f462da4-cc55-47a3-a901-95e55084f4d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 17:56:53,005 - INFO - Carregando dados das curvas de nível de 'alt_curva_de_nivel.csv'...\n",
      "2025-05-26 17:56:55,259 - INFO - Carregado 'alt_curva_de_nivel.csv' com 140426 registros de curvas.\n",
      "2025-05-26 17:56:56,493 - INFO - Curvas de nível válidas e não vazias após limpeza inicial: 140413 (removidas: 0)\n",
      "2025-05-26 17:56:56,498 - INFO - Processadas 140413 curvas de nível válidas (CRS original: EPSG:31982).\n",
      "2025-05-26 17:56:56,513 - INFO - Extensão (bounds) das curvas em EPSG:31982: [ 662031.9262085  7162403.66021729  682796.32299805 7195629.39019775]\n",
      "2025-05-26 17:56:56,518 - INFO - Estatísticas da 'elevation' das CURVAS: Min=862.0, Max=1020.0, Média=904.22, Únicas=154\n",
      "2025-05-26 17:56:56,519 - INFO - Amostra de elevações únicas nas curvas: [909. 911. 912. 921. 913. 873. 914. 916. 981. 982.]\n",
      "2025-05-26 17:56:56,613 - INFO - Carregado e filtrado (COD=521) 'dados_shapes_onibus_urbs_consolidado_threads.csv', resultando em 981 pontos de shapes.\n",
      "2025-05-26 17:56:56,621 - INFO - Rotas de ônibus válidas e não vazias após limpeza inicial: 1 (removidas: 0)\n",
      "2025-05-26 17:56:56,622 - INFO - Reconstruídas 1 geometrias LineString de rotas de ônibus válidas (CRS: EPSG:4326).\n",
      "2025-05-26 17:56:56,623 - INFO - Extensão (bounds) das rotas de ônibus em EPSG:4326: [-49.30835436 -25.49660029 -49.21158915 -25.38537963]\n",
      "2025-05-26 17:56:56,672 - INFO - Curvas de nível já estão no CRS de processamento alvo (EPSG:31982). Nenhuma reprojeção necessária.\n",
      "2025-05-26 17:56:56,681 - INFO - Tentando reprojetar 1 rotas de ônibus de EPSG:4326 para EPSG:31982...\n",
      "2025-05-26 17:56:56,685 - INFO - Rotas de ônibus reprojetadas. Válidas e não vazias: 1 (de 1).\n",
      "2025-05-26 17:56:56,688 - INFO - Iniciando cálculo de elevações para os vértices das rotas de ônibus com até 4 threads (usando CRS: EPSG:31982)...\n",
      "2025-05-26 17:59:34,911 - INFO - Altimetria processada para rota (COD: 20, SHP: 4091). Progresso: 1/1. Vértices com elevação: 981/981\n",
      "2025-05-26 17:59:34,917 - INFO - Cálculo de elevações (com threads) concluído.\n",
      "2025-05-26 17:59:34,944 - INFO - Created 1 records\n",
      "2025-05-26 17:59:34,984 - INFO - Rotas de ônibus com altimetria salvas em: rotas_onibus_com_altimetria_final.gpkg\n",
      "2025-05-26 17:59:34,985 - INFO - Criando mapa interativo com Folium...\n",
      "2025-05-26 17:59:35,015 - INFO - Mapa interativo salvo como: mapa_altimetria_rotas_interativo.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amostra das rotas de ônibus com dados de altimetria:\n",
      "  COD   SHP  min_elevation  max_elevation  mean_elevation  elevation_diff\n",
      "0  20  4091          875.0          990.0      926.989806           115.0\n",
      "\n",
      "Arquivo salvo: rotas_onibus_com_altimetria_final.gpkg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely import wkb\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pyproj import CRS as PyprojCRS # IMPORTANTE: Para manipulação de CRS\n",
    "\n",
    "# Configuração básica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "MAX_WORKERS = 4\n",
    "DEBUG_VERTEX_PROCESSING = False\n",
    "DEBUG_VERTEX_COUNT = 0\n",
    "\n",
    "def parse_wkb_hex(wkb_hex_str):\n",
    "    if pd.isna(wkb_hex_str) or not isinstance(wkb_hex_str, str):\n",
    "        return None\n",
    "    try:\n",
    "        if wkb_hex_str.startswith('0x'):\n",
    "            wkb_hex_str = wkb_hex_str[2:]\n",
    "        return wkb.loads(bytes.fromhex(wkb_hex_str))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "logging.info(\"Carregando dados das curvas de nível de 'alt_curva_de_nivel.csv'...\")\n",
    "# Nome do arquivo ajustado para o que apareceu no último log.\n",
    "caminho_arquivo_curvas = 'alt_curva_de_nivel.csv'\n",
    "gdf_curvas = geopandas.GeoDataFrame()\n",
    "\n",
    "# !!! IMPORTANTE: IDENTIFIQUE O CRS CORRETO DOS SEUS DADOS DE CURVA DE NÍVEL !!!\n",
    "# Baseado nos bounds [662031, 7162403 ...], é PROVAVELMENTE um sistema UTM como EPSG:31982.\n",
    "ORIGINAL_CURVES_CRS_STR = \"EPSG:31982\" # Ex: SIRGAS 2000 / UTM Zone 22S - VERIFIQUE O SEU!\n",
    "\n",
    "try:\n",
    "    df_curvas_raw = pd.read_csv(caminho_arquivo_curvas)\n",
    "    logging.info(f\"Carregado '{caminho_arquivo_curvas}' com {len(df_curvas_raw)} registros de curvas.\")\n",
    "\n",
    "    if 'geom' not in df_curvas_raw.columns or 'elevation' not in df_curvas_raw.columns:\n",
    "        raise ValueError(\"Colunas 'geom' ou 'elevation' não encontradas no arquivo de curvas.\")\n",
    "\n",
    "    df_curvas_raw['geometry'] = df_curvas_raw['geom'].apply(parse_wkb_hex)\n",
    "    df_curvas_raw.dropna(subset=['geometry'], inplace=True)\n",
    "\n",
    "    if not df_curvas_raw.empty:\n",
    "        gdf_curvas = geopandas.GeoDataFrame(df_curvas_raw, geometry='geometry', crs=ORIGINAL_CURVES_CRS_STR)\n",
    "        gdf_curvas['elevation'] = pd.to_numeric(gdf_curvas['elevation'], errors='coerce')\n",
    "        gdf_curvas.dropna(subset=['elevation'], inplace=True)\n",
    "\n",
    "        initial_curve_count = len(gdf_curvas)\n",
    "        gdf_curvas_cleaned = gdf_curvas[gdf_curvas.geometry.is_valid & ~gdf_curvas.geometry.is_empty & gdf_curvas.geometry.notna()].copy()\n",
    "        logging.info(f\"Curvas de nível válidas e não vazias após limpeza inicial: {len(gdf_curvas_cleaned)} (removidas: {initial_curve_count - len(gdf_curvas_cleaned)})\")\n",
    "\n",
    "        if gdf_curvas_cleaned.empty:\n",
    "            logging.error(\"GeoDataFrame de curvas de nível está vazio após limpeza.\")\n",
    "        else:\n",
    "            gdf_curvas = gdf_curvas_cleaned\n",
    "            logging.info(f\"Processadas {len(gdf_curvas)} curvas de nível válidas (CRS original: {gdf_curvas.crs}).\")\n",
    "            logging.info(f\"Extensão (bounds) das curvas em {gdf_curvas.crs}: {gdf_curvas.total_bounds}\")\n",
    "            min_elev, max_elev, mean_elev = gdf_curvas['elevation'].min(), gdf_curvas['elevation'].max(), gdf_curvas['elevation'].mean()\n",
    "            unique_elev_count = gdf_curvas['elevation'].nunique()\n",
    "            unique_elev_sample = gdf_curvas['elevation'].unique()[:min(10, unique_elev_count)]\n",
    "            logging.info(f\"Estatísticas da 'elevation' das CURVAS: Min={min_elev}, Max={max_elev}, Média={mean_elev:.2f}, Únicas={unique_elev_count}\")\n",
    "            logging.info(f\"Amostra de elevações únicas nas curvas: {unique_elev_sample}\")\n",
    "    else:\n",
    "        logging.error(\"Nenhuma geometria válida encontrada no arquivo de curvas de nível após o parse.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Erro geral ao carregar ou processar dados das curvas de nível: {e}\", exc_info=True)\n",
    "\n",
    "caminho_arquivo_shapes_onibus = 'dados_shapes_onibus_urbs_consolidado_threads.csv'\n",
    "gdf_bus_routes = geopandas.GeoDataFrame()\n",
    "try:\n",
    "    df_bus_shapes_points = pd.read_csv(caminho_arquivo_shapes_onibus)\n",
    "    # Mantendo o filtro para COD 521 conforme o último log do usuário\n",
    "    df_bus_shapes_points = df_bus_shapes_points[df_bus_shapes_points['COD'] == 20].reset_index(drop=True)\n",
    "    logging.info(f\"Carregado e filtrado (COD=521) '{caminho_arquivo_shapes_onibus}', resultando em {len(df_bus_shapes_points)} pontos de shapes.\")\n",
    "\n",
    "    df_bus_shapes_points['Latitude'] = pd.to_numeric(df_bus_shapes_points['Latitude'], errors='coerce')\n",
    "    df_bus_shapes_points['Longitude'] = pd.to_numeric(df_bus_shapes_points['Longitude'], errors='coerce')\n",
    "    df_bus_shapes_points.dropna(subset=['Latitude', 'Longitude'], inplace=True)\n",
    "    df_bus_shapes_points['SHP'] = df_bus_shapes_points['SHP'].astype(str)\n",
    "    df_bus_shapes_points['COD'] = df_bus_shapes_points['COD'].astype(str)\n",
    "\n",
    "    bus_route_geometries_list = []\n",
    "    for name, group in df_bus_shapes_points.groupby(['COD', 'SHP'], sort=False):\n",
    "        if len(group) >= 2:\n",
    "            line = LineString(zip(group['Longitude'], group['Latitude']))\n",
    "            bus_route_geometries_list.append({'COD': name[0], 'SHP': name[1], 'geometry': line})\n",
    "        else:\n",
    "            logging.warning(f\"Rota COD {name[0]}, SHP {name[1]} tem {len(group)} ponto(s), não pode formar LineString.\")\n",
    "\n",
    "    if bus_route_geometries_list:\n",
    "        gdf_bus_routes = geopandas.GeoDataFrame(bus_route_geometries_list, geometry='geometry', crs=\"EPSG:4326\")\n",
    "        initial_route_count = len(gdf_bus_routes)\n",
    "        gdf_bus_routes_cleaned = gdf_bus_routes[gdf_bus_routes.geometry.is_valid & ~gdf_bus_routes.geometry.is_empty & gdf_bus_routes.geometry.notna()].copy()\n",
    "        logging.info(f\"Rotas de ônibus válidas e não vazias após limpeza inicial: {len(gdf_bus_routes_cleaned)} (removidas: {initial_route_count - len(gdf_bus_routes_cleaned)})\")\n",
    "        if gdf_bus_routes_cleaned.empty:\n",
    "            logging.error(\"Nenhuma geometria de rota de ônibus válida após limpeza.\")\n",
    "        else:\n",
    "            gdf_bus_routes = gdf_bus_routes_cleaned\n",
    "            logging.info(f\"Reconstruídas {len(gdf_bus_routes)} geometrias LineString de rotas de ônibus válidas (CRS: {gdf_bus_routes.crs}).\")\n",
    "            logging.info(f\"Extensão (bounds) das rotas de ônibus em {gdf_bus_routes.crs}: {gdf_bus_routes.total_bounds}\")\n",
    "    else:\n",
    "        logging.error(\"Nenhuma geometria de rota de ônibus pôde ser reconstruída.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Erro ao carregar/processar shapes de ônibus: {e}\", exc_info=True)\n",
    "\n",
    "TARGET_PROCESSING_CRS_STR = \"EPSG:31982\"\n",
    "TARGET_PROCESSING_CRS_OBJ = PyprojCRS.from_string(TARGET_PROCESSING_CRS_STR) # Objeto CRS para comparação\n",
    "\n",
    "gdf_curvas_proc = geopandas.GeoDataFrame()\n",
    "gdf_bus_routes_proc = geopandas.GeoDataFrame()\n",
    "\n",
    "if not gdf_curvas.empty:\n",
    "    if gdf_curvas.crs and gdf_curvas.crs.equals(TARGET_PROCESSING_CRS_OBJ): # Comparação correta\n",
    "        logging.info(f\"Curvas de nível já estão no CRS de processamento alvo ({TARGET_PROCESSING_CRS_STR}). Nenhuma reprojeção necessária.\")\n",
    "        gdf_curvas_proc = gdf_curvas.copy()\n",
    "    elif gdf_curvas.crs:\n",
    "        logging.info(f\"Tentando reprojetar {len(gdf_curvas)} curvas de nível de {gdf_curvas.crs.to_string()} para {TARGET_PROCESSING_CRS_STR}...\")\n",
    "        try:\n",
    "            gdf_curvas_proc = gdf_curvas.to_crs(TARGET_PROCESSING_CRS_STR)\n",
    "            initial_count_proj = len(gdf_curvas_proc)\n",
    "            gdf_curvas_proc = gdf_curvas_proc[gdf_curvas_proc.geometry.is_valid & ~gdf_curvas_proc.geometry.is_empty & gdf_curvas_proc.geometry.notna()].copy()\n",
    "            cleaned_count_proj = len(gdf_curvas_proc)\n",
    "            logging.info(f\"Curvas de nível reprojetadas. Válidas e não vazias: {cleaned_count_proj} (de {initial_count_proj}).\")\n",
    "            if gdf_curvas_proc.empty and initial_count_proj > 0:\n",
    "                 logging.warning(f\"NENHUMA CURVA DE NÍVEL VÁLIDA RESTOU APÓS REPROJEÇÃO E LIMPEZA.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Falha crítica ao reprojetar gdf_curvas: {e}. gdf_curvas_proc permanecerá vazio.\", exc_info=True)\n",
    "    else:\n",
    "        logging.error(\"gdf_curvas não tem CRS definido. Não é possível reprojetar.\")\n",
    "else:\n",
    "    logging.warning(\"gdf_curvas original estava vazio.\")\n",
    "\n",
    "if not gdf_bus_routes.empty:\n",
    "    if gdf_bus_routes.crs and gdf_bus_routes.crs.equals(TARGET_PROCESSING_CRS_OBJ): # Comparação correta\n",
    "        logging.info(f\"Rotas de ônibus já estão no CRS de processamento alvo ({TARGET_PROCESSING_CRS_STR}).\")\n",
    "        gdf_bus_routes_proc = gdf_bus_routes.copy()\n",
    "    elif gdf_bus_routes.crs:\n",
    "        logging.info(f\"Tentando reprojetar {len(gdf_bus_routes)} rotas de ônibus de {gdf_bus_routes.crs.to_string()} para {TARGET_PROCESSING_CRS_STR}...\")\n",
    "        try:\n",
    "            gdf_bus_routes_proc = gdf_bus_routes.to_crs(TARGET_PROCESSING_CRS_STR)\n",
    "            initial_count_proj = len(gdf_bus_routes_proc)\n",
    "            gdf_bus_routes_proc = gdf_bus_routes_proc[gdf_bus_routes_proc.geometry.is_valid & ~gdf_bus_routes_proc.geometry.is_empty & gdf_bus_routes_proc.geometry.notna()].copy()\n",
    "            cleaned_count_proj = len(gdf_bus_routes_proc)\n",
    "            logging.info(f\"Rotas de ônibus reprojetadas. Válidas e não vazias: {cleaned_count_proj} (de {initial_count_proj}).\")\n",
    "            if gdf_bus_routes_proc.empty and initial_count_proj > 0:\n",
    "                logging.warning(f\"NENHUMA ROTA DE ÔNIBUS VÁLIDA RESTOU APÓS REPROJEÇÃO E LIMPEZA.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Falha crítica ao reprojetar gdf_bus_routes: {e}. gdf_bus_routes_proc permanecerá vazio.\", exc_info=True)\n",
    "    else:\n",
    "        logging.error(\"gdf_bus_routes não tem CRS definido. Não é possível reprojetar.\")\n",
    "else:\n",
    "    logging.warning(\"gdf_bus_routes original estava vazio.\")\n",
    "\n",
    "# --- DIAGNÓSTICO DE AMOSTRAS (Corrigido) ---\n",
    "if not gdf_curvas.empty and gdf_curvas.crs and not gdf_curvas.crs.equals(TARGET_PROCESSING_CRS_OBJ):\n",
    "    logging.info(f\"Diagnóstico de reprojeção para amostras de curvas de nível (de {gdf_curvas.crs.to_string()} para {TARGET_PROCESSING_CRS_STR}):\")\n",
    "    num_samples_to_check = min(3, len(gdf_curvas))\n",
    "    for i in range(num_samples_to_check):\n",
    "        # Para testar to_crs em uma única geometria, é melhor criar uma GeoSeries ou GeoDataFrame temporário\n",
    "        sample_gdf_orig = gdf_curvas.iloc[[i]] # Pega a i-ésima linha como um GeoDataFrame\n",
    "        sample_geom_orig = sample_gdf_orig.geometry.iloc[0]\n",
    "        logging.info(f\"  Amostra Curva {i} (CRS Original: {sample_gdf_orig.crs.to_string()}): Válida={sample_geom_orig.is_valid}, Vazia={sample_geom_orig.is_empty}, Bounds={sample_geom_orig.bounds}\")\n",
    "        try:\n",
    "            sample_gdf_proj = sample_gdf_orig.to_crs(TARGET_PROCESSING_CRS_STR) # Reprojeta o GeoDataFrame de uma linha\n",
    "            sample_geom_proj = sample_gdf_proj.geometry.iloc[0]\n",
    "            logging.info(f\"    -> Amostra Curva {i} (CRS Alvo: {sample_gdf_proj.crs.to_string()}): Válida={sample_geom_proj.is_valid}, Vazia={sample_geom_proj.is_empty}, Bounds={sample_geom_proj.bounds}\")\n",
    "            if not sample_geom_proj.is_valid or sample_geom_proj.is_empty:\n",
    "                logging.warning(f\"      PROBLEMA: Amostra Curva {i} tornou-se inválida/vazia após reprojeção individual.\")\n",
    "        except Exception as e_sample_proj:\n",
    "            logging.error(f\"      ERRO ao reprojetar Amostra Curva {i} individualmente: {e_sample_proj}\")\n",
    "\n",
    "\n",
    "def get_linestring_vertex_elevations(line_geom, gdf_contours_processed, route_cod_shp_for_debug=None):\n",
    "    global DEBUG_VERTEX_COUNT\n",
    "    if line_geom is None or line_geom.is_empty or gdf_contours_processed.empty:\n",
    "        if DEBUG_VERTEX_PROCESSING and DEBUG_VERTEX_COUNT < 5:\n",
    "            logging.debug(f\"DEBUG ({route_cod_shp_for_debug}): get_linestring_vertex_elevations recebeu geometria nula/vazia ou gdf_contours_processed vazio.\")\n",
    "        return []\n",
    "    \n",
    "    gdf_contours_valid = gdf_contours_processed[\n",
    "        gdf_contours_processed.geometry.is_valid & (~gdf_contours_processed.geometry.is_empty)\n",
    "    ]\n",
    "    if gdf_contours_valid.empty:\n",
    "        if DEBUG_VERTEX_PROCESSING and DEBUG_VERTEX_COUNT < 5:\n",
    "            logging.debug(f\"DEBUG ({route_cod_shp_for_debug}): Nenhuma curva de nível VÁLIDA em gdf_contours_processed para comparação.\")\n",
    "        return [] \n",
    "\n",
    "    vertex_elevations = []\n",
    "    coords = []\n",
    "    if line_geom.geom_type == 'LineString':\n",
    "        if hasattr(line_geom, 'coords') and len(list(line_geom.coords)) > 0:\n",
    "             coords.extend(list(line_geom.coords))\n",
    "    elif line_geom.geom_type == 'MultiLineString':\n",
    "        for line_segment in line_geom.geoms:\n",
    "            if hasattr(line_segment, 'coords') and len(list(line_segment.coords)) > 0:\n",
    "                coords.extend(list(line_segment.coords))\n",
    "    if not coords:\n",
    "        if DEBUG_VERTEX_PROCESSING and DEBUG_VERTEX_COUNT < 5:\n",
    "            logging.debug(f\"DEBUG ({route_cod_shp_for_debug}): Nenhuma coordenada extraída da geometria da linha.\")\n",
    "        return []\n",
    "\n",
    "    for i_coord, coord_pair in enumerate(coords):\n",
    "        vertex_point = Point(coord_pair)\n",
    "        if not vertex_point.is_valid or vertex_point.is_empty:\n",
    "            vertex_elevations.append(np.nan)\n",
    "            if DEBUG_VERTEX_PROCESSING and DEBUG_VERTEX_COUNT < 5:\n",
    "                 logging.debug(f\"DEBUG ({route_cod_shp_for_debug}) Vértice {i_coord}: Ponto inválido/vazio {vertex_point.wkt}\")\n",
    "            continue\n",
    "        try:\n",
    "            distances = gdf_contours_valid.geometry.distance(vertex_point)\n",
    "            current_debug_active = DEBUG_VERTEX_PROCESSING and DEBUG_VERTEX_COUNT < 2 \n",
    "            if current_debug_active:\n",
    "                logging.debug(f\"DEBUG ({route_cod_shp_for_debug}) Vértice {i_coord} ({vertex_point.wkt}):\")\n",
    "                logging.debug(f\"  Distâncias calculadas (primeiras 5, se houver): {distances.head().tolist() if not distances.empty else 'N/A'}\")\n",
    "                logging.debug(f\"  Distances.empty: {distances.empty}, Distances.isna().all(): {distances.isna().all() if not distances.empty else 'N/A'}\")\n",
    "\n",
    "            if not distances.empty and distances.notna().any():\n",
    "                valid_distances = distances.dropna()\n",
    "                if not valid_distances.empty:\n",
    "                    nearest_contour_idx = valid_distances.idxmin()\n",
    "                    elevation = gdf_contours_valid.loc[nearest_contour_idx, 'elevation']\n",
    "                    vertex_elevations.append(elevation)\n",
    "                    if current_debug_active:\n",
    "                        logging.debug(f\"  Vértice {i_coord}: Elev. encontrada {elevation} da curva idx {nearest_contour_idx} (dist: {valid_distances.min():.2f})\")\n",
    "                else:\n",
    "                    vertex_elevations.append(np.nan) \n",
    "                    if current_debug_active: logging.debug(f\"  Vértice {i_coord}: Todas as distâncias eram NaN.\")\n",
    "            else:\n",
    "                vertex_elevations.append(np.nan)\n",
    "                if current_debug_active: logging.debug(f\"  Vértice {i_coord}: Series de distâncias vazia ou todas NaN inicialmente.\")\n",
    "        except Exception as e_dist_loop:\n",
    "            vertex_elevations.append(np.nan)\n",
    "            if current_debug_active: logging.debug(f\"  Vértice {i_coord}: Exceção no cálculo de distância/elevação: {e_dist_loop}\")\n",
    "        if current_debug_active: DEBUG_VERTEX_COUNT +=1 \n",
    "    return vertex_elevations\n",
    "\n",
    "if not gdf_bus_routes_proc.empty and not gdf_curvas_proc.empty:\n",
    "    logging.info(f\"Iniciando cálculo de elevações para os vértices das rotas de ônibus com até {MAX_WORKERS} threads (usando CRS: {gdf_bus_routes_proc.crs.to_string()})...\")\n",
    "    total_routes = len(gdf_bus_routes_proc)\n",
    "    temp_vertex_elevations_ordered = [None] * total_routes \n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_index = {}\n",
    "        for original_idx, (_, row_proc) in enumerate(gdf_bus_routes_proc.iterrows()):\n",
    "            debug_id = f\"COD:{row_proc['COD']}-SHP:{row_proc['SHP']}\"\n",
    "            future = executor.submit(get_linestring_vertex_elevations, row_proc['geometry'], gdf_curvas_proc, debug_id)\n",
    "            future_to_index[future] = original_idx\n",
    "\n",
    "        processed_count = 0\n",
    "        for future in as_completed(future_to_index):\n",
    "            original_idx = future_to_index[future]\n",
    "            cod_log = gdf_bus_routes.iloc[original_idx]['COD'] \n",
    "            shp_log = gdf_bus_routes.iloc[original_idx]['SHP']\n",
    "            processed_count += 1\n",
    "            try:\n",
    "                elevs_result = future.result()\n",
    "                temp_vertex_elevations_ordered[original_idx] = elevs_result\n",
    "                if elevs_result and not np.all(np.isnan(elevs_result)): \n",
    "                    logging.info(f\"Altimetria processada para rota (COD: {cod_log}, SHP: {shp_log}). Progresso: {processed_count}/{total_routes}. Vértices com elevação: {len([e for e in elevs_result if pd.notna(e)])}/{len(elevs_result)}\")\n",
    "                else:\n",
    "                    logging.info(f\"Nenhuma elevação válida encontrada para rota (COD: {cod_log}, SHP: {shp_log}). Progresso: {processed_count}/{total_routes}\")\n",
    "            except Exception as exc:\n",
    "                temp_vertex_elevations_ordered[original_idx] = [] \n",
    "                logging.error(f\"Rota (COD: {cod_log}, SHP: {shp_log}) gerou exceção na thread: {exc}\", exc_info=False)\n",
    "                logging.info(f\"Progresso: {processed_count}/{total_routes}\")\n",
    "\n",
    "    if len(temp_vertex_elevations_ordered) == len(gdf_bus_routes):\n",
    "        gdf_bus_routes['vertex_elevations'] = temp_vertex_elevations_ordered\n",
    "        gdf_bus_routes['min_elevation'] = gdf_bus_routes['vertex_elevations'].apply(lambda x: np.min(x) if x and not np.all(np.isnan(x)) else np.nan)\n",
    "        gdf_bus_routes['max_elevation'] = gdf_bus_routes['vertex_elevations'].apply(lambda x: np.max(x) if x and not np.all(np.isnan(x)) else np.nan)\n",
    "        gdf_bus_routes['mean_elevation'] = gdf_bus_routes['vertex_elevations'].apply(lambda x: np.mean(x) if x and not np.all(np.isnan(x)) else np.nan)\n",
    "        gdf_bus_routes['elevation_diff'] = gdf_bus_routes.apply(\n",
    "            lambda r: r['max_elevation'] - r['min_elevation'] if pd.notna(r['max_elevation']) and pd.notna(r['min_elevation']) else np.nan, \n",
    "            axis=1\n",
    "        )\n",
    "        logging.info(\"Cálculo de elevações (com threads) concluído.\")\n",
    "        print(\"\\nAmostra das rotas de ônibus com dados de altimetria:\")\n",
    "        print(gdf_bus_routes[['COD', 'SHP', 'min_elevation', 'max_elevation', 'mean_elevation', 'elevation_diff']].head())\n",
    "\n",
    "        gdf_to_save = gdf_bus_routes.drop(columns=['vertex_elevations'], errors='ignore')\n",
    "        try:\n",
    "            output_filename = \"rotas_onibus_com_altimetria_final.gpkg\"\n",
    "            gdf_to_save.to_file(output_filename, driver=\"GPKG\", layer=\"rotas_onibus_altimetria\")\n",
    "            logging.info(f\"Rotas de ônibus com altimetria salvas em: {output_filename}\")\n",
    "            print(f\"\\nArquivo salvo: {output_filename}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erro ao salvar o arquivo GeoPackage: {e}\", exc_info=True)\n",
    "    else:\n",
    "        logging.error(\"Discrepância no número de resultados das threads e o GeoDataFrame de rotas.\")\n",
    "elif gdf_bus_routes_proc.empty :\n",
    "    logging.warning(\"Nenhuma rota de ônibus válida para processar (após reprojeção/limpeza). Altimetria não calculada.\")\n",
    "elif gdf_curvas_proc.empty :\n",
    "    logging.warning(\"Nenhuma curva de nível válida para processar (após reprojeção/limpeza). Não é possível calcular altimetria.\")\n",
    "# Adicione esta importação no início do seu script, se já não estiver lá:\n",
    "import folium\n",
    "\n",
    "# ... (seu código existente para criar gdf_bus_routes com as colunas de elevação) ...\n",
    "\n",
    "# Supondo que gdf_bus_routes já existe (em EPSG:4326) e contém as colunas de elevação\n",
    "if not gdf_bus_routes.empty and 'mean_elevation' in gdf_bus_routes.columns:\n",
    "    logging.info(\"Criando mapa interativo com Folium...\")\n",
    "    try:\n",
    "        # Folium espera coordenadas em Lat/Lon (EPSG:4326), que é o CRS original de gdf_bus_routes\n",
    "        # Se gdf_bus_routes não estiver em EPSG:4326, reprojete:\n",
    "        # gdf_folium = gdf_bus_routes.to_crs(\"EPSG:4326\")\n",
    "        gdf_folium = gdf_bus_routes # Assumindo que já está em EPSG:4326\n",
    "\n",
    "        # Calcular um ponto central para o mapa\n",
    "        if not gdf_folium.geometry.empty:\n",
    "            map_center_lat = gdf_folium.geometry.unary_union.centroid.y\n",
    "            map_center_lon = gdf_folium.geometry.unary_union.centroid.x\n",
    "            \n",
    "            m = folium.Map(location=[map_center_lat, map_center_lon], zoom_start=12)\n",
    "\n",
    "            # Adicionar as rotas ao mapa\n",
    "            # Para colorir, você precisaria de uma lógica para mapear valores para cores\n",
    "            # Aqui, vamos apenas adicionar com um tooltip\n",
    "            tooltip_fields = ['COD', 'SHP', 'min_elevation', 'max_elevation', 'mean_elevation', 'elevation_diff']\n",
    "            # Remove campos do tooltip que não existem no GeoDataFrame\n",
    "            tooltip_fields = [field for field in tooltip_fields if field in gdf_folium.columns]\n",
    "\n",
    "\n",
    "            folium.GeoJson(\n",
    "                gdf_folium,\n",
    "                name='Rotas de Ônibus com Altimetria',\n",
    "                style_function=lambda feature: {\n",
    "                    'color': 'blue', # Cor padrão, pode ser customizada\n",
    "                    'weight': 3,\n",
    "                    'opacity': 0.7\n",
    "                },\n",
    "                tooltip=folium.GeoJsonTooltip(\n",
    "                    fields=tooltip_fields,\n",
    "                    aliases=[f\"{field.replace('_', ' ').title()}:\" for field in tooltip_fields],\n",
    "                    sticky=False\n",
    "                ),\n",
    "                popup=folium.GeoJsonPopup(\n",
    "                    fields=tooltip_fields,\n",
    "                    aliases=[f\"{field.replace('_', ' ').title()}:\" for field in tooltip_fields],\n",
    "                )\n",
    "            ).add_to(m)\n",
    "\n",
    "            folium.LayerControl().add_to(m)\n",
    "            \n",
    "            map_file_name_interactive = \"mapa_altimetria_rotas_interativo.html\"\n",
    "            m.save(map_file_name_interactive)\n",
    "            logging.info(f\"Mapa interativo salvo como: {map_file_name_interactive}\")\n",
    "        else:\n",
    "            logging.warning(\"Não foi possível criar mapa Folium: geometrias vazias.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao criar mapa interativo: {e}\", exc_info=True)\n",
    "else:\n",
    "    logging.warning(\"Não foi possível criar mapa interativo: gdf_bus_routes está vazio ou falta a coluna 'mean_elevation'.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "296cb52c-83b4-4c94-99f9-d400473e4e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>SHP</th>\n",
       "      <th>geometry</th>\n",
       "      <th>min_elevation</th>\n",
       "      <th>max_elevation</th>\n",
       "      <th>mean_elevation</th>\n",
       "      <th>elevation_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>4146</td>\n",
       "      <td>LINESTRING (-49.25216 -25.40663, -49.25203 -25...</td>\n",
       "      <td>875.0</td>\n",
       "      <td>966.0</td>\n",
       "      <td>916.646454</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  COD   SHP                                           geometry  min_elevation  \\\n",
       "0  22  4146  LINESTRING (-49.25216 -25.40663, -49.25203 -25...          875.0   \n",
       "\n",
       "   max_elevation  mean_elevation  elevation_diff  \n",
       "0          966.0      916.646454            91.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95db7213-c2e5-4b52-acfa-2bc0ba19e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 09:28:23,258 - INFO - Carregando dados das curvas de nível de 'alt_curva_de_nivel.csv'...\n",
      "2025-05-27 09:28:25,806 - INFO - Carregado 'alt_curva_de_nivel.csv' com 140426 registros de curvas.\n",
      "2025-05-27 09:28:27,247 - INFO - Curvas de nível válidas e não vazias após limpeza inicial: 140413 (removidas: 0)\n",
      "2025-05-27 09:28:27,251 - INFO - Processadas 140413 curvas de nível válidas (CRS original: EPSG:31982).\n",
      "2025-05-27 09:28:27,267 - INFO - Extensão (bounds) das curvas em EPSG:31982: [ 662031.9262085  7162403.66021729  682796.32299805 7195629.39019775]\n",
      "2025-05-27 09:28:27,272 - INFO - Estatísticas da 'elevation' das CURVAS: Min=862.0, Max=1020.0, Média=904.22, Únicas=154\n",
      "2025-05-27 09:28:27,273 - INFO - Amostra de elevações únicas nas curvas: [909. 911. 912. 921. 913. 873. 914. 916. 981. 982.]\n",
      "2025-05-27 09:28:27,370 - INFO - Carregado e filtrado (COD=20) 'dados_shapes_onibus_urbs_consolidado_threads.csv', resultando em 973 pontos de shapes.\n",
      "2025-05-27 09:28:27,376 - INFO - Rotas de ônibus válidas e não vazias após limpeza inicial: 1 (removidas: 0)\n",
      "2025-05-27 09:28:27,377 - INFO - Reconstruídas 1 geometrias LineString de rotas de ônibus válidas (CRS: EPSG:4326).\n",
      "2025-05-27 09:28:27,378 - INFO - Extensão (bounds) das rotas de ônibus em EPSG:4326: [-49.30832081 -25.49659989 -49.21538972 -25.4063372 ]\n",
      "2025-05-27 09:28:27,434 - INFO - Curvas de nível já estão no CRS de processamento alvo (EPSG:31982). Nenhuma reprojeção necessária.\n",
      "2025-05-27 09:28:27,441 - INFO - Tentando reprojetar 1 rotas de ônibus de EPSG:4326 para EPSG:31982...\n",
      "2025-05-27 09:28:27,444 - INFO - Rotas de ônibus reprojetadas. Válidas e não vazias: 1 (de 1).\n",
      "2025-05-27 09:28:27,448 - INFO - Iniciando cálculo de elevações para os vértices das rotas de ônibus com até 4 threads (usando CRS: EPSG:31982)...\n",
      "2025-05-27 09:31:20,364 - INFO - Altimetria processada para rota (COD: 22, SHP: 4146). Progresso: 1/1. Vértices com elevação: 973/973\n",
      "2025-05-27 09:31:20,374 - INFO - Cálculo de elevações (com threads) concluído.\n",
      "2025-05-27 09:31:20,406 - INFO - Created 1 records\n",
      "2025-05-27 09:31:20,447 - INFO - Rotas de ônibus com altimetria salvas em: rotas_onibus_com_altimetria_final.gpkg\n",
      "2025-05-27 09:31:20,448 - INFO - Criando mapa interativo com Folium...\n",
      "2025-05-27 09:31:20,488 - INFO - Mapa interativo salvo como: mapa_altimetria_rotas_interativo.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amostra das rotas de ônibus com dados de altimetria:\n",
      "  COD   SHP  min_elevation  max_elevation  mean_elevation  elevation_diff\n",
      "0  22  4146          875.0          966.0      916.646454            91.0\n",
      "\n",
      "Arquivo salvo: rotas_onibus_com_altimetria_final.gpkg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n",
    "from shapely.geometry import Point, LineString # Mantido como no seu script\n",
    "from shapely import wkb\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pyproj import CRS as PyprojCRS # IMPORTANTE: Para manipulação de CRS\n",
    "\n",
    "# Configuração básica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "MAX_WORKERS = 4\n",
    "DEBUG_VERTEX_PROCESSING = False\n",
    "DEBUG_VERTEX_COUNT = 0\n",
    "\n",
    "def parse_wkb_hex(wkb_hex_str):\n",
    "    if pd.isna(wkb_hex_str) or not isinstance(wkb_hex_str, str):\n",
    "        return None\n",
    "    try:\n",
    "        if wkb_hex_str.startswith('0x'):\n",
    "            wkb_hex_str = wkb_hex_str[2:]\n",
    "        return wkb.loads(bytes.fromhex(wkb_hex_str))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "logging.info(\"Carregando dados das curvas de nível de 'alt_curva_de_nivel.csv'...\")\n",
    "# Nome do arquivo ajustado para o que apareceu no último log.\n",
    "caminho_arquivo_curvas = 'alt_curva_de_nivel.csv'\n",
    "gdf_curvas = geopandas.GeoDataFrame()\n",
    "\n",
    "# !!! IMPORTANTE: IDENTIFIQUE O CRS CORRETO DOS SEUS DADOS DE CURVA DE NÍVEL !!!\n",
    "# Baseado nos bounds [662031, 7162403 ...], é PROVAVELMENTE um sistema UTM como EPSG:31982.\n",
    "ORIGINAL_CURVES_CRS_STR = \"EPSG:31982\" # Ex: SIRGAS 2000 / UTM Zone 22S - VERIFIQUE O SEU!\n",
    "\n",
    "try:\n",
    "    df_curvas_raw = pd.read_csv(caminho_arquivo_curvas)\n",
    "    logging.info(f\"Carregado '{caminho_arquivo_curvas}' com {len(df_curvas_raw)} registros de curvas.\")\n",
    "\n",
    "    if 'geom' not in df_curvas_raw.columns or 'elevation' not in df_curvas_raw.columns:\n",
    "        raise ValueError(\"Colunas 'geom' ou 'elevation' não encontradas no arquivo de curvas.\")\n",
    "\n",
    "    df_curvas_raw['geometry'] = df_curvas_raw['geom'].apply(parse_wkb_hex)\n",
    "    df_curvas_raw.dropna(subset=['geometry'], inplace=True)\n",
    "\n",
    "    if not df_curvas_raw.empty:\n",
    "        gdf_curvas = geopandas.GeoDataFrame(df_curvas_raw, geometry='geometry', crs=ORIGINAL_CURVES_CRS_STR)\n",
    "        gdf_curvas['elevation'] = pd.to_numeric(gdf_curvas['elevation'], errors='coerce')\n",
    "        gdf_curvas.dropna(subset=['elevation'], inplace=True)\n",
    "\n",
    "        initial_curve_count = len(gdf_curvas)\n",
    "        gdf_curvas_cleaned = gdf_curvas[gdf_curvas.geometry.is_valid & ~gdf_curvas.geometry.is_empty & gdf_curvas.geometry.notna()].copy()\n",
    "        logging.info(f\"Curvas de nível válidas e não vazias após limpeza inicial: {len(gdf_curvas_cleaned)} (removidas: {initial_curve_count - len(gdf_curvas_cleaned)})\")\n",
    "\n",
    "        if gdf_curvas_cleaned.empty:\n",
    "            logging.error(\"GeoDataFrame de curvas de nível está vazio após limpeza.\")\n",
    "        else:\n",
    "            gdf_curvas = gdf_curvas_cleaned\n",
    "            logging.info(f\"Processadas {len(gdf_curvas)} curvas de nível válidas (CRS original: {gdf_curvas.crs}).\")\n",
    "            logging.info(f\"Extensão (bounds) das curvas em {gdf_curvas.crs}: {gdf_curvas.total_bounds}\")\n",
    "            min_elev, max_elev, mean_elev = gdf_curvas['elevation'].min(), gdf_curvas['elevation'].max(), gdf_curvas['elevation'].mean()\n",
    "            unique_elev_count = gdf_curvas['elevation'].nunique()\n",
    "            unique_elev_sample = gdf_curvas['elevation'].unique()[:min(10, unique_elev_count)]\n",
    "            logging.info(f\"Estatísticas da 'elevation' das CURVAS: Min={min_elev}, Max={max_elev}, Média={mean_elev:.2f}, Únicas={unique_elev_count}\")\n",
    "            logging.info(f\"Amostra de elevações únicas nas curvas: {unique_elev_sample}\")\n",
    "    else:\n",
    "        logging.error(\"Nenhuma geometria válida encontrada no arquivo de curvas de nível após o parse.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Erro geral ao carregar ou processar dados das curvas de nível: {e}\", exc_info=True)\n",
    "\n",
    "caminho_arquivo_shapes_onibus = 'dados_shapes_onibus_urbs_consolidado_threads.csv'\n",
    "gdf_bus_routes = geopandas.GeoDataFrame()\n",
    "try:\n",
    "    df_bus_shapes_points = pd.read_csv(caminho_arquivo_shapes_onibus)\n",
    "    # Mantendo o filtro para COD 20 conforme o último log do usuário (ajustado de 521 para 20)\n",
    "    df_bus_shapes_points = df_bus_shapes_points[df_bus_shapes_points['COD'] == 22].reset_index(drop=True)\n",
    "    logging.info(f\"Carregado e filtrado (COD=20) '{caminho_arquivo_shapes_onibus}', resultando em {len(df_bus_shapes_points)} pontos de shapes.\")\n",
    "\n",
    "    df_bus_shapes_points['Latitude'] = pd.to_numeric(df_bus_shapes_points['Latitude'], errors='coerce')\n",
    "    df_bus_shapes_points['Longitude'] = pd.to_numeric(df_bus_shapes_points['Longitude'], errors='coerce')\n",
    "    df_bus_shapes_points.dropna(subset=['Latitude', 'Longitude'], inplace=True)\n",
    "    df_bus_shapes_points['SHP'] = df_bus_shapes_points['SHP'].astype(str)\n",
    "    df_bus_shapes_points['COD'] = df_bus_shapes_points['COD'].astype(str)\n",
    "\n",
    "    bus_route_geometries_list = []\n",
    "    for name, group in df_bus_shapes_points.groupby(['COD', 'SHP'], sort=False):\n",
    "        if len(group) >= 2:\n",
    "            line = LineString(zip(group['Longitude'], group['Latitude']))\n",
    "            bus_route_geometries_list.append({'COD': name[0], 'SHP': name[1], 'geometry': line})\n",
    "        else:\n",
    "            logging.warning(f\"Rota COD {name[0]}, SHP {name[1]} tem {len(group)} ponto(s), não pode formar LineString.\")\n",
    "\n",
    "    if bus_route_geometries_list:\n",
    "        gdf_bus_routes = geopandas.GeoDataFrame(bus_route_geometries_list, geometry='geometry', crs=\"EPSG:4326\")\n",
    "        initial_route_count = len(gdf_bus_routes)\n",
    "        gdf_bus_routes_cleaned = gdf_bus_routes[gdf_bus_routes.geometry.is_valid & ~gdf_bus_routes.geometry.is_empty & gdf_bus_routes.geometry.notna()].copy()\n",
    "        logging.info(f\"Rotas de ônibus válidas e não vazias após limpeza inicial: {len(gdf_bus_routes_cleaned)} (removidas: {initial_route_count - len(gdf_bus_routes_cleaned)})\")\n",
    "        if gdf_bus_routes_cleaned.empty:\n",
    "            logging.error(\"Nenhuma geometria de rota de ônibus válida após limpeza.\")\n",
    "        else:\n",
    "            gdf_bus_routes = gdf_bus_routes_cleaned\n",
    "            logging.info(f\"Reconstruídas {len(gdf_bus_routes)} geometrias LineString de rotas de ônibus válidas (CRS: {gdf_bus_routes.crs}).\")\n",
    "            logging.info(f\"Extensão (bounds) das rotas de ônibus em {gdf_bus_routes.crs}: {gdf_bus_routes.total_bounds}\")\n",
    "    else:\n",
    "        logging.error(\"Nenhuma geometria de rota de ônibus pôde ser reconstruída.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Erro ao carregar/processar shapes de ônibus: {e}\", exc_info=True)\n",
    "\n",
    "TARGET_PROCESSING_CRS_STR = \"EPSG:31982\"\n",
    "TARGET_PROCESSING_CRS_OBJ = PyprojCRS.from_string(TARGET_PROCESSING_CRS_STR) # Objeto CRS para comparação\n",
    "\n",
    "gdf_curvas_proc = geopandas.GeoDataFrame()\n",
    "gdf_bus_routes_proc = geopandas.GeoDataFrame()\n",
    "\n",
    "if not gdf_curvas.empty:\n",
    "    if gdf_curvas.crs and gdf_curvas.crs.equals(TARGET_PROCESSING_CRS_OBJ): # Comparação correta\n",
    "        logging.info(f\"Curvas de nível já estão no CRS de processamento alvo ({TARGET_PROCESSING_CRS_STR}). Nenhuma reprojeção necessária.\")\n",
    "        gdf_curvas_proc = gdf_curvas.copy()\n",
    "    elif gdf_curvas.crs:\n",
    "        logging.info(f\"Tentando reprojetar {len(gdf_curvas)} curvas de nível de {gdf_curvas.crs.to_string()} para {TARGET_PROCESSING_CRS_STR}...\")\n",
    "        try:\n",
    "            gdf_curvas_proc = gdf_curvas.to_crs(TARGET_PROCESSING_CRS_STR)\n",
    "            initial_count_proj = len(gdf_curvas_proc)\n",
    "            gdf_curvas_proc = gdf_curvas_proc[gdf_curvas_proc.geometry.is_valid & ~gdf_curvas_proc.geometry.is_empty & gdf_curvas_proc.geometry.notna()].copy()\n",
    "            cleaned_count_proj = len(gdf_curvas_proc)\n",
    "            logging.info(f\"Curvas de nível reprojetadas. Válidas e não vazias: {cleaned_count_proj} (de {initial_count_proj}).\")\n",
    "            if gdf_curvas_proc.empty and initial_count_proj > 0:\n",
    "                logging.warning(f\"NENHUMA CURVA DE NÍVEL VÁLIDA RESTOU APÓS REPROJEÇÃO E LIMPEZA.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Falha crítica ao reprojetar gdf_curvas: {e}. gdf_curvas_proc permanecerá vazio.\", exc_info=True)\n",
    "    else:\n",
    "        logging.error(\"gdf_curvas não tem CRS definido. Não é possível reprojetar.\")\n",
    "else:\n",
    "    logging.warning(\"gdf_curvas original estava vazio.\")\n",
    "\n",
    "if not gdf_bus_routes.empty:\n",
    "    if gdf_bus_routes.crs and gdf_bus_routes.crs.equals(TARGET_PROCESSING_CRS_OBJ): # Comparação correta\n",
    "        logging.info(f\"Rotas de ônibus já estão no CRS de processamento alvo ({TARGET_PROCESSING_CRS_STR}).\")\n",
    "        gdf_bus_routes_proc = gdf_bus_routes.copy()\n",
    "    elif gdf_bus_routes.crs:\n",
    "        logging.info(f\"Tentando reprojetar {len(gdf_bus_routes)} rotas de ônibus de {gdf_bus_routes.crs.to_string()} para {TARGET_PROCESSING_CRS_STR}...\")\n",
    "        try:\n",
    "            gdf_bus_routes_proc = gdf_bus_routes.to_crs(TARGET_PROCESSING_CRS_STR)\n",
    "            initial_count_proj = len(gdf_bus_routes_proc)\n",
    "            gdf_bus_routes_proc = gdf_bus_routes_proc[gdf_bus_routes_proc.geometry.is_valid & ~gdf_bus_routes_proc.geometry.is_empty & gdf_bus_routes_proc.geometry.notna()].copy()\n",
    "            cleaned_count_proj = len(gdf_bus_routes_proc)\n",
    "            logging.info(f\"Rotas de ônibus reprojetadas. Válidas e não vazias: {cleaned_count_proj} (de {initial_count_proj}).\")\n",
    "            if gdf_bus_routes_proc.empty and initial_count_proj > 0:\n",
    "                logging.warning(f\"NENHUMA ROTA DE ÔNIBUS VÁLIDA RESTOU APÓS REPROJEÇÃO E LIMPEZA.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Falha crítica ao reprojetar gdf_bus_routes: {e}. gdf_bus_routes_proc permanecerá vazio.\", exc_info=True)\n",
    "    else:\n",
    "        logging.error(\"gdf_bus_routes não tem CRS definido. Não é possível reprojetar.\")\n",
    "else:\n",
    "    logging.warning(\"gdf_bus_routes original estava vazio.\")\n",
    "\n",
    "# --- DIAGNÓSTICO DE AMOSTRAS (Corrigido) ---\n",
    "if not gdf_curvas.empty and gdf_curvas.crs and not gdf_curvas.crs.equals(TARGET_PROCESSING_CRS_OBJ):\n",
    "    logging.info(f\"Diagnóstico de reprojeção para amostras de curvas de nível (de {gdf_curvas.crs.to_string()} para {TARGET_PROCESSING_CRS_STR}):\")\n",
    "    num_samples_to_check = min(3, len(gdf_curvas))\n",
    "    for i in range(num_samples_to_check):\n",
    "        sample_gdf_orig = gdf_curvas.iloc[[i]] \n",
    "        sample_geom_orig = sample_gdf_orig.geometry.iloc[0]\n",
    "        logging.info(f\"  Amostra Curva {i} (CRS Original: {sample_gdf_orig.crs.to_string()}): Válida={sample_geom_orig.is_valid}, Vazia={sample_geom_orig.is_empty}, Bounds={sample_geom_orig.bounds}\")\n",
    "        try:\n",
    "            sample_gdf_proj = sample_gdf_orig.to_crs(TARGET_PROCESSING_CRS_STR) \n",
    "            sample_geom_proj = sample_gdf_proj.geometry.iloc[0]\n",
    "            logging.info(f\"    -> Amostra Curva {i} (CRS Alvo: {sample_gdf_proj.crs.to_string()}): Válida={sample_geom_proj.is_valid}, Vazia={sample_geom_proj.is_empty}, Bounds={sample_geom_proj.bounds}\")\n",
    "            if not sample_geom_proj.is_valid or sample_geom_proj.is_empty:\n",
    "                logging.warning(f\"      PROBLEMA: Amostra Curva {i} tornou-se inválida/vazia após reprojeção individual.\")\n",
    "        except Exception as e_sample_proj:\n",
    "            logging.error(f\"      ERRO ao reprojetar Amostra Curva {i} individualmente: {e_sample_proj}\")\n",
    "\n",
    "# --- Funções Adicionadas para Cálculo de Ganho/Perda Cumulativa ---\n",
    "def _calculate_cumulative_elevation_gain(elevations):\n",
    "    \"\"\"Calcula o ganho de elevação cumulativo a partir de uma lista de elevações.\"\"\"\n",
    "    if not isinstance(elevations, list) or not elevations:\n",
    "        return np.nan\n",
    "\n",
    "    valid_elevations = [e for e in elevations if pd.notna(e) and isinstance(e, (int, float))]\n",
    "\n",
    "    if len(valid_elevations) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    cumulative_gain = 0.0\n",
    "    for i in range(1, len(valid_elevations)):\n",
    "        diff = valid_elevations[i] - valid_elevations[i-1]\n",
    "        if diff > 0:\n",
    "            cumulative_gain += diff\n",
    "    return cumulative_gain\n",
    "\n",
    "def _calculate_cumulative_elevation_loss(elevations):\n",
    "    \"\"\"Calcula a perda de elevação cumulativa a partir de uma lista de elevações.\"\"\"\n",
    "    if not isinstance(elevations, list) or not elevations:\n",
    "        return np.nan\n",
    "\n",
    "    valid_elevations = [e for e in elevations if pd.notna(e) and isinstance(e, (int, float))]\n",
    "\n",
    "    if len(valid_elevations) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    cumulative_loss = 0.0\n",
    "    for i in range(1, len(valid_elevations)):\n",
    "        diff = valid_elevations[i] - valid_elevations[i-1]\n",
    "        if diff < 0:\n",
    "            cumulative_loss += abs(diff)\n",
    "    return cumulative_loss\n",
    "# --- Fim das Funções Adicionadas ---\n",
    "\n",
    "def get_linestring_vertex_elevations(line_geom, gdf_contours_processed, route_cod_shp_for_debug=None):\n",
    "    global DEBUG_VERTEX_COUNT\n",
    "    if line_geom is None or line_geom.is_empty or gdf_contours_processed.empty:\n",
    "        if DEBUG_VERTEX_PROCESSING and DEBUG_VERTEX_COUNT < 5:\n",
    "            logging.debug(f\"DEBUG ({route_cod_shp_for_debug}): get_linestring_vertex_elevations recebeu geometria nula/vazia ou gdf_contours_processed vazio.\")\n",
    "        return [] # Retorna lista vazia se não há geometria ou contornos\n",
    "    \n",
    "    # Filtra por geometrias válidas e não vazias DENTRO da função para garantir que sempre trabalhe com dados limpos\n",
    "    gdf_contours_valid = gdf_contours_processed[\n",
    "        gdf_contours_processed.geometry.is_valid & (~gdf_contours_processed.geometry.is_empty)\n",
    "    ]\n",
    "    if gdf_contours_valid.empty:\n",
    "        if DEBUG_VERTEX_PROCESSING and DEBUG_VERTEX_COUNT < 5: # Limita o número de logs para não poluir\n",
    "            logging.debug(f\"DEBUG ({route_cod_shp_for_debug}): Nenhuma curva de nível VÁLIDA em gdf_contours_processed para comparação.\")\n",
    "        return [] # Retorna lista vazia se não há contornos válidos\n",
    "\n",
    "    vertex_elevations = []\n",
    "    coords = []\n",
    "    # Trata LineString e MultiLineString para extrair coordenadas\n",
    "    if line_geom.geom_type == 'LineString':\n",
    "        if hasattr(line_geom, 'coords') and len(list(line_geom.coords)) > 0: # Verifica se há coordenadas\n",
    "            coords.extend(list(line_geom.coords))\n",
    "    elif line_geom.geom_type == 'MultiLineString': # Supondo que MultiLineString foi importado ou tratado\n",
    "        for line_segment in line_geom.geoms:\n",
    "            if hasattr(line_segment, 'coords') and len(list(line_segment.coords)) > 0:\n",
    "                coords.extend(list(line_segment.coords))\n",
    "    \n",
    "    if not coords: # Se nenhuma coordenada foi extraída\n",
    "        if DEBUG_VERTEX_PROCESSING and DEBUG_VERTEX_COUNT < 5:\n",
    "            logging.debug(f\"DEBUG ({route_cod_shp_for_debug}): Nenhuma coordenada extraída da geometria da linha.\")\n",
    "        return []\n",
    "\n",
    "    for i_coord, coord_pair in enumerate(coords):\n",
    "        vertex_point = Point(coord_pair)\n",
    "        if not vertex_point.is_valid or vertex_point.is_empty:\n",
    "            vertex_elevations.append(np.nan)\n",
    "            if DEBUG_VERTEX_PROCESSING and DEBUG_VERTEX_COUNT < 5: # Limita logs\n",
    "                logging.debug(f\"DEBUG ({route_cod_shp_for_debug}) Vértice {i_coord}: Ponto inválido/vazio {vertex_point.wkt}\")\n",
    "            continue\n",
    "        try:\n",
    "            distances = gdf_contours_valid.geometry.distance(vertex_point)\n",
    "            current_debug_active = DEBUG_VERTEX_PROCESSING and DEBUG_VERTEX_COUNT < 2 # Debug mais verboso para os primeiros 2 vértices processados globalmente\n",
    "            \n",
    "            if current_debug_active: # Logging de debug mais detalhado\n",
    "                logging.debug(f\"DEBUG ({route_cod_shp_for_debug}) Vértice {i_coord} ({vertex_point.wkt}):\")\n",
    "                logging.debug(f\"  Distâncias calculadas (primeiras 5, se houver): {distances.head().tolist() if not distances.empty else 'N/A'}\")\n",
    "                logging.debug(f\"  Distances.empty: {distances.empty}, Distances.isna().all(): {distances.isna().all() if not distances.empty else 'N/A'}\")\n",
    "\n",
    "            if not distances.empty and distances.notna().any(): # Verifica se há distâncias válidas\n",
    "                valid_distances = distances.dropna() # Remove NaNs das distâncias\n",
    "                if not valid_distances.empty:\n",
    "                    nearest_contour_idx = valid_distances.idxmin() # Índice da curva mais próxima\n",
    "                    elevation = gdf_contours_valid.loc[nearest_contour_idx, 'elevation']\n",
    "                    vertex_elevations.append(elevation)\n",
    "                    if current_debug_active:\n",
    "                        logging.debug(f\"  Vértice {i_coord}: Elev. encontrada {elevation} da curva idx {nearest_contour_idx} (dist: {valid_distances.min():.2f})\")\n",
    "                else: # Caso raro onde todas as distâncias calculadas são NaN (ex: ponto muito distante)\n",
    "                    vertex_elevations.append(np.nan) \n",
    "                    if current_debug_active: logging.debug(f\"  Vértice {i_coord}: Todas as distâncias eram NaN.\")\n",
    "            else: # Se a série de distâncias estiver vazia ou todas as distâncias forem NaN\n",
    "                vertex_elevations.append(np.nan)\n",
    "                if current_debug_active: logging.debug(f\"  Vértice {i_coord}: Series de distâncias vazia ou todas NaN inicialmente.\")\n",
    "        except Exception as e_dist_loop:\n",
    "            vertex_elevations.append(np.nan)\n",
    "            if current_debug_active: logging.debug(f\"  Vértice {i_coord}: Exceção no cálculo de distância/elevação: {e_dist_loop}\")\n",
    "        \n",
    "        if current_debug_active: DEBUG_VERTEX_COUNT +=1 \n",
    "    return vertex_elevations\n",
    "\n",
    "if not gdf_bus_routes_proc.empty and not gdf_curvas_proc.empty:\n",
    "    logging.info(f\"Iniciando cálculo de elevações para os vértices das rotas de ônibus com até {MAX_WORKERS} threads (usando CRS: {gdf_bus_routes_proc.crs.to_string()})...\")\n",
    "    total_routes = len(gdf_bus_routes_proc)\n",
    "    temp_vertex_elevations_ordered = [None] * total_routes \n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_index = {}\n",
    "        # Usar o índice original de gdf_bus_routes (que corresponde a gdf_bus_routes_proc se não houve filtro que mude a ordem)\n",
    "        for original_idx, (_, row_proc) in enumerate(gdf_bus_routes_proc.iterrows()):\n",
    "            # Para o debug ID, usamos os dados da linha processada, pois o índice de gdf_bus_routes pode não alinhar se houve descarte\n",
    "            debug_id = f\"COD:{row_proc['COD']}-SHP:{row_proc['SHP']}\"\n",
    "            future = executor.submit(get_linestring_vertex_elevations, row_proc['geometry'], gdf_curvas_proc, debug_id)\n",
    "            future_to_index[future] = original_idx # Mapeia o futuro para o índice posicional em temp_vertex_elevations_ordered\n",
    "\n",
    "        processed_count = 0\n",
    "        for future in as_completed(future_to_index):\n",
    "            original_idx = future_to_index[future] # Este é o índice para temp_vertex_elevations_ordered e gdf_bus_routes\n",
    "            # Para logging, pegar COD/SHP de gdf_bus_routes original usando o índice original que foi preservado.\n",
    "            cod_log = gdf_bus_routes.iloc[original_idx]['COD'] \n",
    "            shp_log = gdf_bus_routes.iloc[original_idx]['SHP']\n",
    "            processed_count += 1\n",
    "            try:\n",
    "                elevs_result = future.result()\n",
    "                temp_vertex_elevations_ordered[original_idx] = elevs_result\n",
    "                \n",
    "                # Verifica se elevs_result não é None e contém alguma elevação não-NaN\n",
    "                if elevs_result and not np.all(np.isnan(elevs_result)): \n",
    "                    logging.info(f\"Altimetria processada para rota (COD: {cod_log}, SHP: {shp_log}). Progresso: {processed_count}/{total_routes}. Vértices com elevação: {len([e for e in elevs_result if pd.notna(e)])}/{len(elevs_result)}\")\n",
    "                else:\n",
    "                    logging.info(f\"Nenhuma elevação válida encontrada para rota (COD: {cod_log}, SHP: {shp_log}). Progresso: {processed_count}/{total_routes}\")\n",
    "            except Exception as exc:\n",
    "                temp_vertex_elevations_ordered[original_idx] = [] # Lista vazia em caso de erro na thread\n",
    "                logging.error(f\"Rota (COD: {cod_log}, SHP: {shp_log}) gerou exceção na thread: {exc}\", exc_info=False)\n",
    "                logging.info(f\"Progresso: {processed_count}/{total_routes}\") # Log de progresso mesmo em erro\n",
    "\n",
    "    # Atribuir os resultados de volta ao gdf_bus_routes original (que está em EPSG:4326)\n",
    "    if len(temp_vertex_elevations_ordered) == len(gdf_bus_routes):\n",
    "        gdf_bus_routes['vertex_elevations'] = temp_vertex_elevations_ordered\n",
    "        # Corrigido para usar np.nanmin, np.nanmax, np.nanmean que ignoram NaNs corretamente.\n",
    "        # A lambda precisa verificar se x é uma lista e se contém algum valor não-NaN.\n",
    "        gdf_bus_routes['min_elevation'] = gdf_bus_routes['vertex_elevations'].apply(\n",
    "            lambda x: np.nanmin([val for val in x if pd.notna(val)]) if isinstance(x, list) and any(pd.notna(val) for val in x) else np.nan)\n",
    "        gdf_bus_routes['max_elevation'] = gdf_bus_routes['vertex_elevations'].apply(\n",
    "            lambda x: np.nanmax([val for val in x if pd.notna(val)]) if isinstance(x, list) and any(pd.notna(val) for val in x) else np.nan)\n",
    "        gdf_bus_routes['mean_elevation'] = gdf_bus_routes['vertex_elevations'].apply(\n",
    "            lambda x: np.nanmean([val for val in x if pd.notna(val)]) if isinstance(x, list) and any(pd.notna(val) for val in x) else np.nan)\n",
    "        \n",
    "        gdf_bus_routes['elevation_diff'] = gdf_bus_routes.apply(\n",
    "            lambda r: r['max_elevation'] - r['min_elevation'] if pd.notna(r['max_elevation']) and pd.notna(r['min_elevation']) else np.nan, \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # --- Adição do cálculo de ganho/perda cumulativa ---\n",
    "        gdf_bus_routes['cumulative_gain'] = gdf_bus_routes['vertex_elevations'].apply(_calculate_cumulative_elevation_gain)\n",
    "        gdf_bus_routes['cumulative_loss'] = gdf_bus_routes['vertex_elevations'].apply(_calculate_cumulative_elevation_loss)\n",
    "        # --- Fim da adição ---\n",
    "\n",
    "        logging.info(\"Cálculo de elevações (com threads) concluído.\")\n",
    "        print(\"\\nAmostra das rotas de ônibus com dados de altimetria:\")\n",
    "        # A linha abaixo permanece inalterada conforme a solicitação\n",
    "        print(gdf_bus_routes[['COD', 'SHP', 'min_elevation', 'max_elevation', 'mean_elevation', 'elevation_diff']].head())\n",
    "\n",
    "        gdf_to_save = gdf_bus_routes.drop(columns=['vertex_elevations'], errors='ignore')\n",
    "        try:\n",
    "            output_filename = \"rotas_onibus_com_altimetria_final.gpkg\"\n",
    "            gdf_to_save.to_file(output_filename, driver=\"GPKG\", layer=\"rotas_onibus_altimetria\")\n",
    "            logging.info(f\"Rotas de ônibus com altimetria salvas em: {output_filename}\")\n",
    "            print(f\"\\nArquivo salvo: {output_filename}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erro ao salvar o arquivo GeoPackage: {e}\", exc_info=True)\n",
    "    else:\n",
    "        logging.error(\"Discrepância no número de resultados das threads e o GeoDataFrame de rotas.\")\n",
    "elif gdf_bus_routes_proc.empty :\n",
    "    logging.warning(\"Nenhuma rota de ônibus válida para processar (após reprojeção/limpeza). Altimetria não calculada.\")\n",
    "elif gdf_curvas_proc.empty :\n",
    "    logging.warning(\"Nenhuma curva de nível válida para processar (após reprojeção/limpeza). Não é possível calcular altimetria.\")\n",
    "\n",
    "# Adicione esta importação no início do seu script, se já não estiver lá:\n",
    "import folium # Já importado no início do script original completo, mas garantindo aqui.\n",
    "\n",
    "# ... (seu código existente para criar gdf_bus_routes com as colunas de elevação) ...\n",
    "\n",
    "# Supondo que gdf_bus_routes já existe (em EPSG:4326) e contém as colunas de elevação\n",
    "if not gdf_bus_routes.empty and 'mean_elevation' in gdf_bus_routes.columns:\n",
    "    logging.info(\"Criando mapa interativo com Folium...\")\n",
    "    try:\n",
    "        gdf_folium = gdf_bus_routes \n",
    "\n",
    "        if not gdf_folium.geometry.empty:\n",
    "            # Tenta calcular o centroide de forma mais robusta, ignorando geometrias vazias/inválidas\n",
    "            valid_geoms_for_centroid = gdf_folium[gdf_folium.geometry.is_valid & ~gdf_folium.geometry.is_empty]\n",
    "            if not valid_geoms_for_centroid.empty:\n",
    "                 map_center_lat = valid_geoms_for_centroid.geometry.unary_union.centroid.y\n",
    "                 map_center_lon = valid_geoms_for_centroid.geometry.unary_union.centroid.x\n",
    "            else: # Fallback se não houver geometrias válidas\n",
    "                logging.warning(\"Nenhuma geometria válida para calcular o centroide do mapa Folium. Usando (0,0).\")\n",
    "                map_center_lat, map_center_lon = 0,0\n",
    "            \n",
    "            m = folium.Map(location=[map_center_lat, map_center_lon], zoom_start=12)\n",
    "\n",
    "            tooltip_fields = ['COD', 'SHP', 'min_elevation', 'max_elevation', 'mean_elevation', 'elevation_diff']\n",
    "            tooltip_fields = [field for field in tooltip_fields if field in gdf_folium.columns]\n",
    "\n",
    "\n",
    "            folium.GeoJson(\n",
    "                gdf_folium,\n",
    "                name='Rotas de Ônibus com Altimetria',\n",
    "                style_function=lambda feature: {\n",
    "                    'color': 'blue', \n",
    "                    'weight': 3,\n",
    "                    'opacity': 0.7\n",
    "                },\n",
    "                tooltip=folium.GeoJsonTooltip(\n",
    "                    fields=tooltip_fields,\n",
    "                    aliases=[f\"{field.replace('_', ' ').title()}:\" for field in tooltip_fields],\n",
    "                    sticky=False,\n",
    "                    localize=True # Para melhor formatação de números\n",
    "                ),\n",
    "                popup=folium.GeoJsonPopup(\n",
    "                    fields=tooltip_fields,\n",
    "                    aliases=[f\"{field.replace('_', ' ').title()}:\" for field in tooltip_fields],\n",
    "                    localize=True\n",
    "                )\n",
    "            ).add_to(m)\n",
    "\n",
    "            folium.LayerControl().add_to(m)\n",
    "            \n",
    "            map_file_name_interactive = \"mapa_altimetria_rotas_interativo.html\"\n",
    "            m.save(map_file_name_interactive)\n",
    "            logging.info(f\"Mapa interativo salvo como: {map_file_name_interactive}\")\n",
    "        else:\n",
    "            logging.warning(\"Não foi possível criar mapa Folium: geometrias vazias em gdf_folium.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao criar mapa interativo: {e}\", exc_info=True)\n",
    "else:\n",
    "    logging.warning(\"Não foi possível criar mapa interativo: gdf_bus_routes está vazio ou falta a coluna 'mean_elevation'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7536df2-1d1b-4256-a27f-db0faf27df7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD</th>\n",
       "      <th>SHP</th>\n",
       "      <th>geometry</th>\n",
       "      <th>vertex_elevations</th>\n",
       "      <th>min_elevation</th>\n",
       "      <th>max_elevation</th>\n",
       "      <th>mean_elevation</th>\n",
       "      <th>elevation_diff</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>cumulative_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>4146</td>\n",
       "      <td>LINESTRING (-49.25216 -25.40663, -49.25203 -25...</td>\n",
       "      <td>[912.0, 912.0, 911.0, 910.0, 910.0, 909.0, 908...</td>\n",
       "      <td>875.0</td>\n",
       "      <td>966.0</td>\n",
       "      <td>916.646454</td>\n",
       "      <td>91.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>612.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  COD   SHP                                           geometry  \\\n",
       "0  22  4146  LINESTRING (-49.25216 -25.40663, -49.25203 -25...   \n",
       "\n",
       "                                   vertex_elevations  min_elevation  \\\n",
       "0  [912.0, 912.0, 911.0, 910.0, 910.0, 909.0, 908...          875.0   \n",
       "\n",
       "   max_elevation  mean_elevation  elevation_diff  cumulative_gain  \\\n",
       "0          966.0      916.646454            91.0            612.0   \n",
       "\n",
       "   cumulative_loss  \n",
       "0            612.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_bus_routes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
